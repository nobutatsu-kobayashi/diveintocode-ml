{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint22 RNNスクラッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Activation():\n",
    "    def __init__(self, name='tanh'):\n",
    "        self.name = name\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if self.name == 'sigmoid':\n",
    "            return self.sigmoid(X)\n",
    "        elif self.name == 'tanh':\n",
    "            return self.tanh(X)\n",
    "        elif self.name == 'relu':\n",
    "            return self.relu(X)\n",
    "        \n",
    "    def backward(self, X, dy):\n",
    "        if self.name == 'sigmoid':\n",
    "            return self.d_sigmoid(X) * dy\n",
    "        elif self.name == 'tanh':\n",
    "            return self.d_tanh(X) * dy\n",
    "        elif self.name == 'relu':\n",
    "            return self.d_relu(X) * dy\n",
    "        \n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def d_sigmoid(self, X):\n",
    "        return self.sigmoid(X) * (1 - self.sigmoid(X))\n",
    "    \n",
    "    def tanh(self, X):\n",
    "        return (np.exp(X) - np.exp(-X)) / (np.exp(X) + np.exp(-X))\n",
    "    \n",
    "    def d_tanh(self, X):\n",
    "        return 1 - self.tanh(X)**2\n",
    "    \n",
    "    def relu(self, X):\n",
    "        self.mask = X > 0\n",
    "        return X * self.mask\n",
    "    \n",
    "    def d_relu(self, X):\n",
    "        return 1 * (X > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    def __init__(self, units, input_dim, initializer='xavier'):\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "        self.initializer = initializer\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def sigma(self, initializer, layer_in, layer_out):\n",
    "        if initializer == 'xavier':\n",
    "            return np.sqrt(2 / (layer_in + layer_out))\n",
    "        elif initializer == 'he':\n",
    "            return np.sqrt(2 / layer_in)\n",
    "        \n",
    "    def initialize_params(self):\n",
    "        self.W = np.random.randn(self.input_dim, self.units)*self.sigma(self.initializer, self.input_dim, self.units)\n",
    "        self.b = np.random.randn(1, self.units)*self.sigma(self.initailizer, self.input_dim, self.units)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Z = np.dot(X, self.W) + self.b\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, X, delta):\n",
    "        n_samples = delta.shape[0]\n",
    "        self.dW = np.dot(X.T, delta) / n_samples\n",
    "        self.db = np.dot(np.ones([1, n_samples]), delta) / n_samples\n",
    "        dX = np.dot(delta, self.W.T)\n",
    "        return dX\n",
    "    \n",
    "    def update(self, lr):\n",
    "        self.W -= lr * self.dW\n",
    "        self.b -= lr * self.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題1】SimpleRNNのフォワードプロパゲーション実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN:\n",
    "    # def __init__(self, nodes, input_dim, activation='tanh', initializer='xavier'):\n",
    "    def __init__(self, nodes, input_dim, activation='tanh'):\n",
    "        self.nodes = nodes\n",
    "        self.input_dim = input_dim\n",
    "        self.activation = activation\n",
    "        # self.initializer = initializer\n",
    "        self.activate_function = Activation(self.activation)\n",
    "        self.W_x = None\n",
    "        self.W_h = None\n",
    "        self.b = None\n",
    "        self.X = None\n",
    "        self.Z = None\n",
    "        self.X_post = None\n",
    "        \n",
    "#     def sigma(self, initializer, layer_in, layer_out):\n",
    "#         if initializer == 'xavier':\n",
    "#             return np.sqrt(2 / (layer_in + layer_out))\n",
    "#         elif initializer == 'he':\n",
    "#             return np.sqrt(2 / layer_in)\n",
    "        \n",
    "#     def initialize_params(self):\n",
    "#         self.W_x = np.random.randn(self.input_dim, self.nodes)*self.sigma(self.initializer, self.input_dim, self.nodes)\n",
    "#         self.W_h = np.random.randn(self.nodes, self.nodes)*self.sigma(initializer, self.nodes, self.nodes)\n",
    "#         self.b = np.random.randn(1, self.nodes)*self.sigma(self.initializer, self.input_dim, self.nodes)\n",
    "        \n",
    "    def forward(self, W_x, W_h, b, X):\n",
    "        self.W_x = W_x\n",
    "        self.W_h = W_h\n",
    "        self.b = b\n",
    "        self.X = X\n",
    "        batch_size, n_sequences, n_features = X.shape\n",
    "        Z = np.zeros((batch_size, n_sequences, self.nodes))\n",
    "        # Z = np.zeros((batch_size, self.nodes))\n",
    "        X_post = np.zeros(Z.shape)\n",
    "        \n",
    "#         for t in range(n_sequences):\n",
    "#             if t == 0:\n",
    "#                 Z[:, t, :] = np.dot(X[:, t, :], self.W_x) + self.b\n",
    "#             else:\n",
    "#                 Z[:, t, :] = np.dot(X[:, t, :], self.W_x) + np.dot(X_post[:, t-1, :], self.W_h) + self.b\n",
    "#             X_post[:, t, :] = self.activate_function.forward(Z[:, t, :])\n",
    "#         # 取り出せるようにZ, X_postを保存\n",
    "#         self.Z = Z\n",
    "#         self.X_post = X_post\n",
    "#         return Z\n",
    "\n",
    "        for t in range(n_sequences):\n",
    "            if t == 0:\n",
    "                Z[:,t,:] = np.dot(X[:,t,:], self.W_x) + self.b\n",
    "            else:\n",
    "                Z[:,t,:] = np.dot(X[:,t,:], self.W_x) + np.dot(X_post[:,t-1,:], self.W_h) + self.b\n",
    "            X_post[:, t, :] = self.activate_function.forward(Z[:, t, :])\n",
    "        return X_post[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5345224838248488"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigma(layer_in, layer_out):\n",
    "    return np.sqrt(2 / (layer_in + layer_out))\n",
    "\n",
    "sigma(layer_in=3, layer_out=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.59052423,  0.75578933, -1.1275052 , -0.55735179]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *self.sigma(self.initializer, self.input_dim, self.units)\n",
    "np.random.randn(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.0007, 1.0013, 1.0019, 1.0023],\n",
       "        [1.0011, 1.0021, 1.0031, 1.0038],\n",
       "        [1.0015, 1.0029, 1.0043, 1.0053]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(w_x, w_h, bias, X):\n",
    "    a, b, c = X.shape\n",
    "    Z = np.zeros((a, b, 4))\n",
    "    for t in range(b):\n",
    "        Z[:, t, :] = np.dot(X[:, t, :], w_x) + bias\n",
    "    return Z\n",
    "\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100\n",
    "bias = np.array([1, 1, 1, 1])\n",
    "X = np.array([[[1, 2], [2, 3], [3, 4]]])/100\n",
    "\n",
    "test(w_x, w_h, bias, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(X):\n",
    "    batch_size, n_sequences, n_features = X.shape\n",
    "    Z = np.zeros((batch_size, n_sequences, 4))\n",
    "    return Z\n",
    "\n",
    "x = np.array([[[1, 2], [2, 3], [3, 4]]]) / 100\n",
    "\n",
    "forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題2】小さな配列でのフォワードプロパゲーションの実験**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
    "batch_size = x.shape[0] # 1\n",
    "n_sequences = x.shape[1] # 3\n",
    "n_features = x.shape[2] # 2\n",
    "n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
    "b = np.array([1, 1, 1, 1]) # (n_nodes,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01 0.02]]\n",
      "[[0.02 0.03]]\n",
      "[[0.03 0.04]]\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 0, :])\n",
    "print(x[:, 1, :])\n",
    "print(x[:, 2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = SimpleRNN(units=4, input_dim=(1, 3, 2))\n",
    "h = rnn.forward(w_x, w_h, b, x)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題3】（アドバンス課題）バックプロパゲーションの実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN2:\n",
    "    def __init__(self, nodes, input_dim, activation='tanh', initializer='xavier'):\n",
    "        self.nodes = nodes\n",
    "        self.input_dim = input_dim\n",
    "        self.activation = activation\n",
    "        self.activate_function = Activation(activation)\n",
    "        self.W_x = None\n",
    "        self.W_h = None\n",
    "        self.b = None\n",
    "        self.dW_x = None\n",
    "        self.dW_h = None\n",
    "        self.db = None\n",
    "        self.X = None\n",
    "        self.Z = None\n",
    "        self.X_post = None\n",
    "        \n",
    "        def sigma(self, initializer, layer_in, layer_out):\n",
    "            if initializer == 'xavier':\n",
    "                return np.sqrt(2 / (layer_in + layer_out))\n",
    "            elif initializer == 'he':\n",
    "                return np.sqrt(2 / layer_in)\n",
    "            \n",
    "        def initialize_params(self):\n",
    "            self.W_x = np.random.randn(self.input_dim, self.nodes)*self.sigma(self.initializer, self.input_dim, self.nodes)\n",
    "            self.W_h = np.random.randn(self.nodes, self.nodes)*self.sigma(initializer, self.nodes, self.nodes)\n",
    "            self.b = np.random.randn(1, self.nodes)*self.sigma(self.initializer, self.input_dim, self.nodes)\n",
    "        \n",
    "        def forward(self, X):\n",
    "            self.W_x = W_x\n",
    "            self.W_h = W_h\n",
    "            self.b = b\n",
    "            self.X = X\n",
    "            batch_size, n_sequences, n_features = X.shape\n",
    "            Z = np.zeros((batch_size, n_sequences, self.nodes))\n",
    "            X_post = np.zeros(Z.shape)\n",
    "            \n",
    "            for t in range(n_sequences):\n",
    "                if t == 0:\n",
    "                    Z[:, t, :] = np.dot(X[:, t, :], self.W_x) + self.b\n",
    "                else:\n",
    "                    Z[:, t, :] = np.dot(X[:, t, :], self.W_x) + np.dot(X_post[:, t-1, :], self.W_h) + self.b\n",
    "                X_post[:, t, :] = self.activate_function.forward(Z[:, t, :])\n",
    "            self.Z = Z\n",
    "            self.X_post = X_post\n",
    "            return X[:, -1, :]\n",
    "        \n",
    "        def backward(self, _dX_post):\n",
    "            batch_size, n_sequences, n_features = _dX_post.shape\n",
    "            \n",
    "            dX_post = np.zeros((batch_size, n_sequences, n_features))\n",
    "            dX_post[:-1,:] = _dX_post.copy()\n",
    "            \n",
    "            self.dW_x = np.zeros(self.W_x.shape)\n",
    "            self.dW_h = np.zeros(self.W_h.shape)\n",
    "            self.b = np.zeros(self.b.shape)\n",
    "            delta = np.zeros(dX_post.shape)\n",
    "            dX = np.zeros(self.X.shape)\n",
    "            \n",
    "            for t in range(n_sequences-1,-1,-1):\n",
    "                if t == n_sequences-1:\n",
    "                    delta[:,t,:] = self.activate_function.backward(self.Z[:,t,:], dX_post[:,t,:])\n",
    "                else:\n",
    "                    delta[:,t,:] = self.activate_function.backward(self.Z[:,t,:], dX_post[:,t,:] + np.dot(delta[:,t+1,:], self.W_h))\n",
    "                dX[:,t,:] = np.dot(delta[:,t,:], self.W_x.T)\n",
    "                \n",
    "            for t in range(n_sequences):\n",
    "                if t != 0:\n",
    "                    self.W_h += np.dot(self.X_post[:,t-1,:].T, delta[:,t,:]) / batch_size\n",
    "                self.dW_x += np.dot(self.X[:,t,:].T, delta[:,t,:]) / batch_size\n",
    "                self.db += np.dot(np.ones((1, batch_size)), delta[:,t,:]) / batch_size\n",
    "                \n",
    "            return dX\n",
    "        \n",
    "        def update(self, lr):\n",
    "            self.W_x -= lr * self.dW_x\n",
    "            self.W_h -= lr * self.dW_h\n",
    "            self.b -= lr * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
