{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN スクラッチ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.fit_transform(y_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train_one_hot\n",
    "y_test = y_test_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  7  2 -2]\n"
     ]
    }
   ],
   "source": [
    "inp = np.array([2, 3, 5, 7, 4, 2])\n",
    "fil = np.array([-1, 0, 1])\n",
    "\n",
    "XS = inp.size\n",
    "FS = fil.size\n",
    "\n",
    "OS = XS - FS + 1\n",
    "x = []\n",
    "\n",
    "for fs in range(FS+1):\n",
    "    x.append(np.dot(inp[fs:fs+FS], fil))\n",
    "\n",
    "x = np.array(x)\n",
    "print(x+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  4. -1. -5.]\n",
      " [14. 22. 25. 14.]\n",
      " [ 7. 11. 17. 18.]\n",
      " [39. 62. 85. 69.]]\n"
     ]
    }
   ],
   "source": [
    "inp = np.array([2, 3, 5, 7, 4, 2])\n",
    "fil = np.array([[-1, 0, 1], [0, 3, 1], [2, 1, 0], [5, 8, 1]])\n",
    "#fil = np.array([-1, 0, 1])\n",
    "\n",
    "XS = inp.size\n",
    "FN, FS = fil.shape\n",
    "\n",
    "OS = XS - FS + 1\n",
    "\n",
    "xh = np.zeros((FN, OS))\n",
    "for fs in range(FS+1):\n",
    "    for fn in range(FN):\n",
    "        xh[fn][fs] = np.dot(inp[fs:fs+OS-1], fil[fn])\n",
    "print(xh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[ 50.  80. 110.]\n",
      "30\n",
      "110\n",
      "170\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "db = np.sum(da)\n",
    "print(db)\n",
    "\n",
    "dw_0 = np.dot(da, x[0:2])\n",
    "dw_1 = np.dot(da, x[1:3])\n",
    "dw_2 = np.dot(da, x[2:4])\n",
    "# print(dw_0)\n",
    "# print(dw_1)\n",
    "# print(dw_2)\n",
    "\n",
    "dw = np.zeros(w.size)\n",
    "for i in range(w.size):\n",
    "    dw[i] = np.dot(da, x[i:i+(x.size-w.size+1)])\n",
    "print(dw)\n",
    "\n",
    "dx_0 = da[0] * w[0]\n",
    "dx_1 = da[0] * w[1] + da[1] * w[0]\n",
    "dx_2 = da[0] * w[2] + da[1] * w[1]\n",
    "dx_3 = da[1] * w[2]\n",
    "print(dx_0)\n",
    "print(dx_1)\n",
    "print(dx_2)\n",
    "print(dx_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34. 49.]\n"
     ]
    }
   ],
   "source": [
    "# print(np.dot(x[0:3], w) + b)\n",
    "# print(np.dot(x[1:4], w) + b)\n",
    "os = x.size - w.size + 1\n",
    "xh = np.zeros(os,)\n",
    "for i in range(os):\n",
    "    xh[i] = np.dot(x[i:i+w.size], w)\n",
    "print(xh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    def __init__(self, FN, FS, initializer, optimizer):\n",
    "        self.FN = FN\n",
    "        self.FS = FS\n",
    "        self.optimizer = optimizer\n",
    "        self.initializer = initializer\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.F = initializer.F(self.FN, self.FS)\n",
    "        self.b = initializer.b(self.FN)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.S = X.size\n",
    "        # 出力サイズ\n",
    "        self.OS = self.S - self.FS + 1\n",
    "        if self.FN >= 2:\n",
    "            # フィルター数、出力サイズの空箱を用意\n",
    "            xh = np.zeros((self.FN, self.OS))\n",
    "            for fs in range(self.FS+1):\n",
    "                for fn in range(self.FN):\n",
    "                    xh[fn][fs] = np.dot(self.X[fs:fs+OS-1], self.F[fn])\n",
    "            A = xh + self.b\n",
    "            \n",
    "        else:\n",
    "            xh = np.zeros(self.OS,)\n",
    "            for i in range(self.OS):\n",
    "                xh[i] = np.dot(X[i:i+self.FS], self.F)\n",
    "            A = xh + self.b\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dF = np.zeros(self.FS)\n",
    "        for i in range(self.FS):\n",
    "            dF[i] = np.dot(dA, self.X[i:i+(self.S - self.FS + 1)])\n",
    "        db = np.sum(dA)\n",
    "        self = self.optimizer.update(self)\n",
    "        return dF, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def F(self, FN, FS):\n",
    "        F = self.sigma * np.random.randn(FN, FS)\n",
    "        return F\n",
    "    \n",
    "    def b(self, FN):\n",
    "        b = np.random.randn(FN)\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        layer.F -= self.lr * (layer.dF)\n",
    "        layer.b -= self.lr * (layer.db)\n",
    "        return layer.b, layer.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題2】1次元畳み込み後の出力サイズの計算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_size(X, F, pad, stride):\n",
    "    S = X.size\n",
    "    FS = F.shape[1]\n",
    "    P = pad\n",
    "    S = stride\n",
    "    n_out = ((S + 2*P - FS) / S) + 1\n",
    "    return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題3】小さな配列での1次元畳み込み層の実験**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, w, b):\n",
    "    S = X.size\n",
    "        \n",
    "    # 出力サイズ\n",
    "    OS = S - 3 + 1\n",
    "        \n",
    "    # フィルター数、出力サイズの空箱を用意\n",
    "    xh = np.zeros((1, OS))\n",
    "    for fs in range(4):\n",
    "        xh[fs] = np.dot(X[fs:fs+3], w)\n",
    "    A = xh + b\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, w, b):\n",
    "        S = X.size\n",
    "        if w.ndim >= 2:\n",
    "            OS = S - w.shape[1] + 1\n",
    "            # フィルター数、出力サイズの空箱を用意\n",
    "            xh = np.zeros((w.shape[0], OS))\n",
    "            for fs in range(w.shape[1]+1):\n",
    "                for fn in range(w.shape[0]):\n",
    "                    xh[fn][fs] = np.dot(X[fs:fs+OS-1], w[fn])\n",
    "            A = xh + b\n",
    "            \n",
    "        else:\n",
    "            OS = S - w.size + 1\n",
    "            xh = np.zeros(OS,)\n",
    "            for i in range(OS):\n",
    "                xh[i] = np.dot(X[i:i+w.size], w)\n",
    "            A = xh + b\n",
    "        \n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35., 50.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(x, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.array([2, 3, 5, 7, 4, 2])\n",
    "fil = np.array([[-1, 0, 1], [0, 3, 1], [2, 1, 0], [5, 8, 1]])\n",
    "bb = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  6.,  2., -1.],\n",
       "       [15., 24., 28., 18.],\n",
       "       [ 8., 13., 20., 22.],\n",
       "       [40., 64., 88., 73.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(inp, fil, bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, w, b, dA):\n",
    "        dF = np.zeros(w.size)\n",
    "        for i in range(w.size):\n",
    "            dF[i] = np.dot(dA, X[i:i+(X.size - w.size + 1)])\n",
    "        db = np.sum(dA)\n",
    "        #self = self.optimizer.update(self)\n",
    "        return dF, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "\n",
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 50.,  80., 110.]), 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward(x, w, b, delta_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((3, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    def __init__(self, FN, FS, initializer, optimizer):\n",
    "        self.FN = FN\n",
    "        self.FS = FS\n",
    "        self.optimizer = optimizer\n",
    "        self.initializer = initializer\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.F = initializer.F(self.FN, self.FS)\n",
    "        self.b = initializer.b(self.FN)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.S = X.shape[1]\n",
    "        # 出力サイズ\n",
    "        self.OS = self.S - self.FS + 1\n",
    "        if self.FN >= 2:\n",
    "            # フィルター数、出力サイズの空箱を用意\n",
    "            xh = np.zeros((self.FN, self.OS))\n",
    "            for fs in range(self.FS+1):\n",
    "                for fn in range(self.FN):\n",
    "                    xh[fn][fs] = np.dot(self.X[fs:fs+OS-1], self.F[fn])\n",
    "            A = xh + self.b\n",
    "            \n",
    "        else:\n",
    "            xh = np.zeros(self.OS,)\n",
    "            for i in range(self.OS):\n",
    "                xh[i] = np.dot(X[i:i+self.FS], self.F)\n",
    "            A = xh + self.b\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dF = np.zeros(self.FS)\n",
    "        for i in range(self.FS):\n",
    "            dF[i] = np.dot(dA, self.X[i:i+(self.S - self.FS + 1)])\n",
    "        db = np.sum(dA)\n",
    "        self = self.optimizer.update(self)\n",
    "        return dF, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n",
      "22.0\n",
      "17.0\n",
      "23.0\n",
      "18.0\n",
      "24.0\n"
     ]
    }
   ],
   "source": [
    "xh = np.zeros((3, 2))\n",
    "y_00 = np.dot(x[0][0:3], w[0][0]) + np.dot(x[1][0:3], w[0][0]) + 1\n",
    "y_01 = np.dot(x[0][1:4], w[0][0]) + np.dot(x[1][1:4], w[0][1]) + 1\n",
    "y_10 = np.dot(x[0][0:3], w[1][0]) + np.dot(x[1][0:3], w[1][0]) + 2\n",
    "y_11 = np.dot(x[0][1:4], w[1][0]) + np.dot(x[1][1:4], w[1][1]) + 2\n",
    "y_20 = np.dot(x[0][0:3], w[2][0]) + np.dot(x[1][0:3], w[2][0]) + 3\n",
    "y_21 = np.dot(x[0][1:4], w[2][0]) + np.dot(x[1][1:4], w[2][1]) + 3\n",
    "print(y_00)\n",
    "print(y_01)\n",
    "print(y_10)\n",
    "print(y_11)\n",
    "print(y_20)\n",
    "print(y_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, w, b):\n",
    "        S = X.shape[1]\n",
    "        if w.ndim >= 2:\n",
    "            OS = S - w.shape[1] + 1\n",
    "            # フィルター数、出力サイズの空箱を用意\n",
    "            xh = np.zeros((OS, w.shape[0]))\n",
    "            for fs in range(OS):\n",
    "                for fn in range(w.shape[0]):\n",
    "                    xh[fs][fn] += np.dot(X[fn][fs:fs+OS], w[fs][fn])\n",
    "            A = xh\n",
    "            \n",
    "        else:\n",
    "            OS = S - w.size + 1\n",
    "            xh = np.zeros(OS,)\n",
    "            for i in range(OS):\n",
    "                xh[i] = np.dot(X[i:i+w.size], w)\n",
    "            A = xh + b\n",
    "        \n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [5 6 7]]\n",
      "[[2 3 4]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "print(x[0:2, 0:3])\n",
    "print(x[0:3, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2. 3. 4.]\n",
      "  [6. 7. 8.]]\n",
      "\n",
      " [[6. 7. 8.]\n",
      "  [6. 7. 8.]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "xh = np.zeros((2, 2, 3))\n",
    "for oh in range(2):\n",
    "    for ow in range(2):\n",
    "        xh[oh, :, :] = x[oh:oh+2, ow:ow+3]\n",
    "print(xh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnzation(x, FH, FW):\n",
    "    H, W = x.shape\n",
    "    OH = H - FH + 1\n",
    "    OW = W - FW + 1\n",
    "    \n",
    "    xh = np.zeros((FH, FW, OH, OW))\n",
    "    for fh in range(FH):\n",
    "        for fw in range(FW):\n",
    "            xh[fh, fw, :, :] = x[fh:fh+OH, fw:fw+OW]\n",
    "    xt = xh.transpose(2, 3, 0, 1)\n",
    "    return xt.reshape(OH, OW, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "x_col = columnzation(x, 2, 3)\n",
    "x_co = x_col.reshape(2, 6)\n",
    "x_co.shape\n",
    "print(x_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n",
      "[[1 2 3 4 5 6]\n",
      " [2 3 4 3 8 1]\n",
      " [1 7 3 2 4 1]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[[1, 2, 3], [4, 5, 6]], [[2, 3, 4], [3, 8, 1]], [[1, 7, 3], [2, 4, 1]]])\n",
    "w_new = w.reshape(3, -1)\n",
    "print(w.shape)\n",
    "print(w_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106. 127.]\n",
      " [ 90. 111.]\n",
      " [ 65.  83.]]\n",
      "[[106. 127.]\n",
      " [ 90. 111.]\n",
      " [ 65.  83.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(w_new, x_co.T))\n",
    "print(np.dot(x_co, w_new.T).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cforward(x, F, b):\n",
    "    C, S = x.shape\n",
    "    FC = F.shape[1]\n",
    "    FS = F.shape[2]\n",
    "    OC = C - FC + 1\n",
    "    OS = S - FS + 1\n",
    "    \n",
    "    xh = np.zeros((FC, FS, OC, OS))\n",
    "    for fh in range(FC):\n",
    "        for fw in range(FS):\n",
    "            xh[fh, fw, :, :] = x[fh:fh+OC, fw:fw+OS]\n",
    "    xt = xh.transpose(2, 3, 0, 1)\n",
    "    x_col = xt.reshape(OC, OS, -1)\n",
    "    \n",
    "    x_col_new = x_col.reshape(C, -1)\n",
    "    w_new = w.reshape(F.shape[0], -1)\n",
    "    A = np.dot(x_col_new, w_new.T).T + b.reshape(b.size, -1)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "w = np.ones((3, 2, 3))\n",
    "b = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cforward(x, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# これはこれでいいけど、1dに特化した形で書いた方がわかりやすい\n",
    "\n",
    "# class SimpleConv1d:\n",
    "#     def __init__(self, FN, FS, initializer, optimizer):\n",
    "#         self.FN = FN\n",
    "#         self.FS = FS\n",
    "#         self.optimizer = optimizer\n",
    "#         self.initializer = initializer\n",
    "#         # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "#         self.F = initializer.F(self.FN, self.FS)\n",
    "#         self.b = initializer.b(self.FN)\n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         C, S = X.shape\n",
    "#         FC = self.F.shape[1]\n",
    "#         FS = self.F.shape[2]\n",
    "#         OC = C - FH + 1\n",
    "#         OS = S - FW + 1\n",
    "    \n",
    "#         xh = np.zeros((FC, FS, OC, OS))\n",
    "#         for fh in range(FC):\n",
    "#             for fw in range(FS):\n",
    "#                 xh[fh, fw, :, :] = X[fh:fh+OC, fw:fw+OS]\n",
    "#         xt = xh.transpose(2, 3, 0, 1)\n",
    "#         x_col = xt.reshape(OC, OS, -1)\n",
    "    \n",
    "#         x_col_new = x_col.reshape(C, -1)\n",
    "#         w_new = self.F.reshape(F.shape[0], -1)\n",
    "#         A = np.dot(x_col_new, w_new.T).T + self.b.reshape(self.b.size, -1)\n",
    "    \n",
    "#         return A\n",
    "    \n",
    "#     def backward(self, dA):\n",
    "#         dF = np.zeros(self.FS)\n",
    "#         for i in range(self.FS):\n",
    "#             dF[i] = np.dot(dA, self.X[i:i+(self.S - self.FS + 1)])\n",
    "#         db = np.sum(dA)\n",
    "#         self = self.optimizer.update(self)\n",
    "#         return dF, db\n",
    "    \n",
    "    \n",
    "class SimpleInitializer:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def F(self, FN, FS):\n",
    "        F = self.sigma * np.random.randn(FN, FS)\n",
    "        return F\n",
    "    \n",
    "    def b(self, FN):\n",
    "        b = np.random.randn(FN)\n",
    "        return b\n",
    "    \n",
    "    \n",
    "class SGD:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        layer.F -= self.lr * (layer.dF)\n",
    "        layer.b -= self.lr * (layer.db)\n",
    "        return layer.b, layer.b\n",
    "    \n",
    "    \n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        C = np.max(x)\n",
    "        y = np.exp(x / C) / np.exp(x / C).sum(axis=1).reshape(-1, 1)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, y, t):\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        batch_size = self.y.shape[0]\n",
    "        self.loss = -np.sum(t * np.log(y+1e-7)) / batch_size\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx\n",
    "    \n",
    "    \n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.mask = X > 0\n",
    "        A = X * self.mask\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dZ = dA * self.mask\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xavier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def W(self, input_size, input_channel, filter_size, n_filters):\n",
    "        self.sigma = 1 / (np.sqrt(input_size))\n",
    "        W = self.sigma * np.random.randn(n_filters, input_channel, filter_size)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def b(self, n_filters):\n",
    "        b = self.sigma * np.random.randn(n_filters)\n",
    "        \n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimlpeConv1d_():\n",
    "    def __init__(self, input_num, filter_num, optimizer, initializer):\n",
    "        self.padding = 0\n",
    "        self.stride = 1\n",
    "        \n",
    "        self.input_num = input_num\n",
    "        self.C = self.input_num[0]\n",
    "        self.N = self.input_num[1]\n",
    "        \n",
    "        self.filter_num = filter_num\n",
    "        self.FN = filter_num[0]\n",
    "        self.FS = self.filter_num[2]\n",
    "        \n",
    "        self.outputs = self.output_size()\n",
    "        self.initializer = initializer()\n",
    "        \n",
    "        self.W = np.ones((3, 2, 3))\n",
    "        self.b = np.array([1, 2, 3])\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.indexes = np.array([np.arange(i, i+self.filter_num[2]) for i in range(self.outputs)]).astype(np.int)\n",
    "        \n",
    "        self.H_W = 0\n",
    "        self.H_B = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        \n",
    "        X_col = np.zeros((self.outputs, self.FS*self.C))\n",
    "        for i in range(self.C):\n",
    "            X_col[:self.outputs, i*self.FS:i*self.FS+self.FS] = X[i][self.indexes]\n",
    "        w_1 = self.W.reshape(-1, self.C*self.FS)\n",
    "        \n",
    "        A = (np.dot(X_col, w_1.T) + self.b).T\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        self.db = dA.sum(axis=1)\n",
    "        \n",
    "        indexes = np.array([np.arange(i, i+self.filter_num[2]) for i in range(self.outputs)]).astype(np.int)\n",
    "        \n",
    "        dX = np.zeros((2, 4))\n",
    "        for i in range(self.C):\n",
    "            w_1 = w.transpose(1, 0, 2)\n",
    "            X_col = np.dot(w_1[i].T, dA)\n",
    "            for j in range(self.outputs):\n",
    "                dX[i, j:j+self.FS] += X_col.T[j,:]\n",
    "                \n",
    "        X_col = np.zeros((self.C, self.FS*self.outputs))\n",
    "        for i in range(self.C):\n",
    "            X_col[:self.outputs, i*self.FS:i*self.FS+self.FS] = self.X[i][self.indexes]\n",
    "            \n",
    "        K = np.dot(dA, X_col)\n",
    "        self.dW = K.reshape(self.FN, -1, self.FS)\n",
    "        \n",
    "        return dX\n",
    "    \n",
    "    def output_size(self):\n",
    "        return (self.input_num[1]+2*self.padding-self.filter_num[2])//self.stride+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "w = np.ones((3, 2, 3))\n",
    "b = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad():\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        H_W = (layer.H_W + layer.dW * layer.dW)\n",
    "        H_B = (layer.H_B + layer.db * layer.db)\n",
    "        \n",
    "        layer.W -= (self.lr / np.sqrt(H_W)) * layer.dW\n",
    "        layer.b -= (self.lr / np.sqrt(H_B)) * layer.db\n",
    "        layer.H_W = H_W\n",
    "        layer.H_B = H_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = SimlpeConv1d_(input_num=(2, 4), filter_num=(3, 2, 3), optimizer=AdaGrad(), initializer=Xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題5】（アドバンス課題）パディングの実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "np.pad(a, [1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4 0]\n",
      " [0 5 6 7 8 0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1, 5)\n",
    "b = np.arange(5, 9)\n",
    "a_pad = np.pad(a, [1, 1])\n",
    "b_pad = np.pad(b, [1, 1])\n",
    "c = np.vstack([a_pad, b_pad])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cforward(x, F, b, stride=1, pad=0):\n",
    "    C, S = x.shape\n",
    "    #print(C, S)\n",
    "    FH = F.shape[1]\n",
    "    FW = F.shape[2]\n",
    "    OH = (C + 2*pad - FH) // stride + 1\n",
    "    OW = (S + 2*pad - FW) // stride + 1\n",
    "    print('FH:', FH)\n",
    "    print('FW:', FW)\n",
    "    print('OH:', OH)\n",
    "    print('OW:', OW)\n",
    "    \n",
    "    if pad != 0:\n",
    "        x_0 = np.pad(x[0], [pad, pad])\n",
    "        x_1 = np.pad(x[1], [pad, pad])\n",
    "        x = np.vstack([x_0, x_1])\n",
    "        print(x)\n",
    "    xh = np.zeros((FH, FW, OH, OW))\n",
    "    print(xh)\n",
    "    for fh in range(FH):\n",
    "        for fw in range(FW):\n",
    "            xh[fh, fw, :, :] = x[fh:fh+OH, fw:fw+OW]\n",
    "    print('xh:', xh.shape)\n",
    "    xt = xh.transpose(2, 3, 0, 1)\n",
    "    x_col = xt.reshape(OH, OW, -1)\n",
    "    \n",
    "    x_col_new = x_col.reshape(C, -1)\n",
    "    w_new = w.reshape(F.shape[0], -1)\n",
    "    print('x_col_new:', x_col_new.shape)\n",
    "    A = np.dot(x_col_new, w_new.T).T + b.reshape(b.size, -1)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "w = np.ones((3, 2, 3))\n",
    "b = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cforward(x, w, b, stride=1, pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.b -= self.lr * layer.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC():\n",
    "    \n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.W = self.initializer.W(n_nodes1, n_nodes2)\n",
    "        self.b = self.initializer.b(n_nodes2)\n",
    "        \n",
    "        self.H_W = 0\n",
    "        self.H_B = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        A = np.dot(X, self.W) + self.b\n",
    "        self.input = X\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dZ = np.dot(dA, self.W.T)\n",
    "        self.dW = np.dot(self.input.T, dA)\n",
    "        self.db = dA.sum(axis=0)\n",
    "        \n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.mask = X > 0\n",
    "        A = X * self.mask\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dZ = dA * self.mask\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return np.exp(X) / (np.exp(X).sum(axis=1).reshape(-1, 1))\n",
    "    \n",
    "    def backward(self, Z, y):\n",
    "        dA = Z - y\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Xavier():\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "    \n",
    "#     def W(self, input_size, input_channel, filter_size, n_filters):\n",
    "#         self.sigma = 1 / (np.sqrt(input_size))\n",
    "#         W = self.sigma * np.random.randn(n_filters, input_channel, filter_size)\n",
    "        \n",
    "#         return W\n",
    "    \n",
    "#     def b(self, n_filters):\n",
    "#         b = self.sigma * np.random.randn(n_filters)\n",
    "        \n",
    "#         return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xavier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def W(self, n_nodes1, filter_size):\n",
    "        self.sigma = 1 / (np.sqrt(n_nodes1))\n",
    "        W = self.sigma * np.random.randn(filter_size)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def b(self):\n",
    "        b = self.sigma * np.random.randn()\n",
    "        \n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class He():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def b(self, n_nodes2):\n",
    "        b = self.sigma * np.random.randn(n_nodes2)\n",
    "        \n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad():\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        H_W = (layer.H_W + layer.dW * layer.dW)\n",
    "        H_B = (layer.H_B + layer.db * layer.db)\n",
    "        \n",
    "        layer.W -= (self.lr / np.sqrt(H_W)) * layer.dW\n",
    "        layer.b -= (self.lr / np.sqrt(H_B)) * layer.db\n",
    "        layer.H_W = H_W\n",
    "        layer.H_B = H_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDNN:\n",
    "    def __init__(self, layers, activation, epochs=30, batch_size=100, verbose=True):\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "        # mini_batchを取得\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                \n",
    "                # 順伝播\n",
    "                Z = self.forward(mini_X)\n",
    "                \n",
    "                #逆伝播\n",
    "                # softmaxを想定\n",
    "                dA = self.activation[-1].backward(Z, mini_y)\n",
    "                dZ = self.layers[-1].backward(dA)\n",
    "                \n",
    "                for j in range(2, len(self.layers)+1):\n",
    "                    dA = self.activation[-j].backward(dZ)\n",
    "                    dZ = self.layers[-j].backward(dA)\n",
    "                    \n",
    "            y_pred = self.forward(X)\n",
    "            loss_value = self.loss_function(y, y_pred)\n",
    "            self.loss.append(loss_value)\n",
    "            \n",
    "            if X_val is not None:\n",
    "                y_val_pred = self.forward(X_val)\n",
    "                val_loss_value = self.loss_function(y_val, y_val_pred)\n",
    "                self.val_loss.append(val_loss_value)\n",
    "                \n",
    "            if self.verbose:\n",
    "                if X_val is not None:\n",
    "                    print('epoch{}    loss: {}    val_loss: {}'.format(i+1, loss_value, val_loss_value))\n",
    "                else:\n",
    "                    print('epoch{}    loss: {}'.format(i+1, loss_value))\n",
    "                    \n",
    "    def predict(self, X):\n",
    "        pred = self.forward(X).argmax(axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Z = X\n",
    "        for i in range(len(self.layers)):\n",
    "            A = self.layers[i].forward(Z)\n",
    "            Z = self.activation[i].forward(A)\n",
    "            \n",
    "        return Z\n",
    "    \n",
    "    def loss_function(self, t, y_pred):\n",
    "        delta = 1e-7\n",
    "        L = -(t * np.log(y_pred+delta)).sum() / y_pred.shape[0]\n",
    "        \n",
    "        return L\n",
    "    \n",
    "    def normalize(self, X):\n",
    "        return (X - X.min()) / (X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d():\n",
    "    \n",
    "    def __init__(self, input_size, filter_size, optimizer, initializer=Xavier):\n",
    "        \n",
    "        self.padding = 0\n",
    "        self.stride = 1\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.filter_size = filter_size\n",
    "        self.output_size = self.output_()\n",
    "        self.initializer = initializer()\n",
    "        \n",
    "        self.W = self.initializer.W(self.input_size, self.filter_size)\n",
    "        self.b = self.initializer.b()\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.H_W = 0\n",
    "        self.H_B = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        indexes = np.array([np.arange(i, i+self.filter_size) for i in range(self.output_size)]).astype(np.int)\n",
    "            \n",
    "        X = X.reshape(-1)\n",
    "        return (((X[indexes])*(self.W.reshape(1, -1))).sum(axis=1) + self.b).reshape(1, -1)\n",
    "        \n",
    "    def backward(self, dA):\n",
    "        indexes = np.array([np.arange(i, i+self.filter_size) for i in range(self.output_size)]).astype(np.int)\n",
    "        self.dW = ((self.X.reshape(-1)[indexes]*(dA.reshape(-1, 1))).sum(axis=0)).reshape(-1)\n",
    "        self.db = dA.sum()\n",
    "        dX = np.zeros(self.X.shape[1])\n",
    "        for i in range(self.output_size):\n",
    "            dX[i:i+self.filter_size] += (dA[:, i][0])*self.W\n",
    "        self = self.optimizer.update(self)\n",
    "            \n",
    "        return dX\n",
    "        \n",
    "    def output_(self):\n",
    "        return (self.input_size+2*self.padding-self.filter_size)//self.stride+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class equal():\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return X\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 784\n",
    "\n",
    "sigma = 0.01\n",
    "layers = []\n",
    "activation = []\n",
    "optimizer = AdaGrad(lr=0.01)\n",
    "\n",
    "layers.append(FC(n_features, 600, He(), optimizer=optimizer))\n",
    "activation.append(ReLU())\n",
    "layers.append(FC(600, 400, He(), optimizer=optimizer))\n",
    "activation.append(ReLU())\n",
    "layers.append(SimpleConv1d(input_size=400, filter_size=3, optimizer=SGD(), initializer=Xavier))\n",
    "activation.append(equal())\n",
    "layers.append(FC(398, 200, He(), optimizer=optimizer))\n",
    "activation.append(ReLU())\n",
    "layers.append(FC(200, 10, He(), optimizer=optimizer))\n",
    "activation.append(Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kobayashishintachi/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1    loss: nan    val_loss: nan\n",
      "epoch2    loss: nan    val_loss: nan\n",
      "epoch3    loss: nan    val_loss: nan\n",
      "epoch4    loss: nan    val_loss: nan\n",
      "epoch5    loss: nan    val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "dnn = ScratchDNN(layers=layers, activation=activation, epochs=5)\n",
    "dnn.fit(X_train[0].reshape(1, -1), y_train[0].reshape(1, -1), X_test[0].reshape(1, -1), y_test[0].reshape(1, -1))\n",
    "y_pred = dnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
