{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sprint 深層学習スクラッチ ニューラルネットワーク**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. MNISTデータセット**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train[0].dtype)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray', vmin=0, vmax=255)\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前処理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape)\n",
    "print(y_train_one_hot.shape)\n",
    "print(y_train_one_hot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n",
      "48000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. ニューラルネットワークスクラッチ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練用データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題1】重みの初期値を決めるコードの作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: (784, 400)\n",
      "b1: (400,)\n",
      "W2 (400, 200)\n",
      "b2: (200,)\n",
      "W3: (200, 10)\n",
      "b3: (10,)\n"
     ]
    }
   ],
   "source": [
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "sigma = 0.01\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "b1 = np.random.rand(400)\n",
    "print('W1:', W1.shape)\n",
    "print('b1:', b1.shape)\n",
    "n_nodes2 = 200\n",
    "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "b2 = np.random.rand(200)\n",
    "print('W2', W2.shape)\n",
    "print('b2:', b2.shape)\n",
    "n_output = 10\n",
    "W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
    "b3 = np.random.rand(10)\n",
    "print('W3:', W3.shape)\n",
    "print('b3:', b3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['W1'] = sigma * np.random.randn(n_features, n_nodes1)\n",
    "params['b1'] = np.random.rand(400)\n",
    "params['W2'] = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "params['b2'] = np.random.rand(200)\n",
    "params['W3'] = sigma * np.random.randn(n_nodes2, n_output)\n",
    "params['b3'] = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.00900359, -0.01698344,  0.01577815, ..., -0.01156267,\n",
       "         -0.01673465,  0.00758476],\n",
       "        [-0.00618201,  0.01212179, -0.00106411, ..., -0.01254448,\n",
       "         -0.01770738, -0.00223043],\n",
       "        [-0.00654712,  0.00886941, -0.00084888, ..., -0.00081965,\n",
       "         -0.00926552, -0.00120646],\n",
       "        ...,\n",
       "        [-0.01642478,  0.01190158,  0.01055693, ...,  0.00958934,\n",
       "          0.00470071, -0.00631738],\n",
       "        [-0.01069113, -0.00465046,  0.00118049, ...,  0.00243923,\n",
       "         -0.00063011, -0.00531278],\n",
       "        [-0.00851809,  0.01189183,  0.00399869, ...,  0.00321873,\n",
       "         -0.00551489,  0.00675309]]),\n",
       " 'b1': array([0.80670469, 0.37606445, 0.96980889, 0.08965196, 0.32706812,\n",
       "        0.22834845, 0.01010139, 0.90764538, 0.92973047, 0.74621593,\n",
       "        0.5723325 , 0.92582866, 0.94928094, 0.13147006, 0.5146992 ,\n",
       "        0.73143411, 0.2484141 , 0.77806545, 0.28751105, 0.04273808,\n",
       "        0.00671549, 0.91370561, 0.4830459 , 0.91599033, 0.14165461,\n",
       "        0.15788574, 0.10706755, 0.65463226, 0.26395925, 0.18181724,\n",
       "        0.2460106 , 0.90647985, 0.74883176, 0.09773743, 0.68358244,\n",
       "        0.99947911, 0.45517689, 0.55561887, 0.5111823 , 0.37933503,\n",
       "        0.31152442, 0.10919837, 0.25521896, 0.8871856 , 0.02864728,\n",
       "        0.20733692, 0.46335261, 0.33932044, 0.76687118, 0.44733397,\n",
       "        0.19195634, 0.36576034, 0.85663276, 0.42100332, 0.8488535 ,\n",
       "        0.63236802, 0.38156623, 0.30311935, 0.47299942, 0.6998108 ,\n",
       "        0.05522627, 0.09218726, 0.29403464, 0.98175734, 0.34943279,\n",
       "        0.61178287, 0.95458292, 0.28648637, 0.19424195, 0.02702411,\n",
       "        0.4619005 , 0.09568826, 0.86780176, 0.06307296, 0.17656228,\n",
       "        0.61049999, 0.66107459, 0.93747334, 0.2882683 , 0.44822998,\n",
       "        0.0564293 , 0.17646683, 0.45102973, 0.0718802 , 0.78230665,\n",
       "        0.78319073, 0.68409939, 0.49065273, 0.31827343, 0.4978271 ,\n",
       "        0.89232689, 0.05557209, 0.76721291, 0.9291945 , 0.46655107,\n",
       "        0.37952794, 0.36615535, 0.49513973, 0.3796982 , 0.76419627,\n",
       "        0.81526983, 0.29020097, 0.00154585, 0.7072057 , 0.8791138 ,\n",
       "        0.98311155, 0.31847867, 0.33059353, 0.87413503, 0.32566509,\n",
       "        0.0724877 , 0.03246169, 0.27302294, 0.64934257, 0.64844155,\n",
       "        0.14859344, 0.69639347, 0.99019855, 0.70801454, 0.08014984,\n",
       "        0.48252053, 0.70923755, 0.77083925, 0.48242188, 0.38715539,\n",
       "        0.12100941, 0.07853197, 0.72308098, 0.07695974, 0.89255896,\n",
       "        0.35681584, 0.57741552, 0.0775416 , 0.81829859, 0.05424712,\n",
       "        0.20884516, 0.00433822, 0.78150032, 0.15298546, 0.15061678,\n",
       "        0.15229949, 0.74639286, 0.8739975 , 0.89204805, 0.76404517,\n",
       "        0.92135656, 0.54024541, 0.97022355, 0.73476075, 0.59825724,\n",
       "        0.73053546, 0.30195949, 0.05403552, 0.34715059, 0.75263919,\n",
       "        0.47561102, 0.71227935, 0.27283905, 0.507896  , 0.45954286,\n",
       "        0.01534788, 0.60559676, 0.35547696, 0.67069634, 0.07940417,\n",
       "        0.48992143, 0.69258983, 0.53370638, 0.18045012, 0.70615803,\n",
       "        0.82122033, 0.25662165, 0.01975475, 0.58066828, 0.09297063,\n",
       "        0.52779589, 0.94616004, 0.74270268, 0.53566551, 0.10201037,\n",
       "        0.24448194, 0.46906894, 0.71100569, 0.25595525, 0.90385027,\n",
       "        0.92046176, 0.07509204, 0.82565911, 0.10664102, 0.19285432,\n",
       "        0.34499483, 0.72490959, 0.02783978, 0.66089676, 0.2682943 ,\n",
       "        0.08813274, 0.47862602, 0.51607112, 0.66530368, 0.13041684,\n",
       "        0.64517746, 0.26348939, 0.20161409, 0.59114057, 0.60200906,\n",
       "        0.16564724, 0.77928258, 0.85356797, 0.05768202, 0.59936179,\n",
       "        0.26920798, 0.03336967, 0.59983176, 0.48185457, 0.923961  ,\n",
       "        0.39265485, 0.04589335, 0.64144093, 0.22252608, 0.73888575,\n",
       "        0.99437121, 0.31837436, 0.71537614, 0.55613623, 0.22047989,\n",
       "        0.25185473, 0.12239106, 0.72444361, 0.37835936, 0.08591558,\n",
       "        0.85484517, 0.46175299, 0.83255827, 0.52691102, 0.65963186,\n",
       "        0.76949995, 0.76223719, 0.53198303, 0.98692075, 0.20393371,\n",
       "        0.16250641, 0.82379648, 0.91257023, 0.72530041, 0.25740369,\n",
       "        0.77466577, 0.52105947, 0.87784595, 0.09545005, 0.26176238,\n",
       "        0.75056575, 0.11621006, 0.44278212, 0.77499142, 0.92863445,\n",
       "        0.23724654, 0.08837368, 0.3199203 , 0.16023681, 0.10152406,\n",
       "        0.64627951, 0.41548731, 0.21711338, 0.50902882, 0.79439938,\n",
       "        0.16441799, 0.869278  , 0.60773472, 0.06760422, 0.94373777,\n",
       "        0.48940978, 0.80731063, 0.79679278, 0.71840573, 0.26251921,\n",
       "        0.35673334, 0.20325764, 0.52558566, 0.72784519, 0.74839727,\n",
       "        0.08677318, 0.90732856, 0.32208843, 0.84020057, 0.73327696,\n",
       "        0.95685304, 0.2808548 , 0.90189234, 0.56513631, 0.65072806,\n",
       "        0.34502135, 0.79157205, 0.92678572, 0.15129526, 0.76363908,\n",
       "        0.42815795, 0.58921861, 0.31450673, 0.64279522, 0.98866732,\n",
       "        0.02661456, 0.23277692, 0.20096619, 0.9676505 , 0.03076133,\n",
       "        0.25642458, 0.6844264 , 0.49846724, 0.68941102, 0.54934516,\n",
       "        0.51032692, 0.87356214, 0.87881485, 0.81547229, 0.55285884,\n",
       "        0.27527238, 0.14681152, 0.03189957, 0.6718014 , 0.44144951,\n",
       "        0.62332288, 0.11905841, 0.6173894 , 0.37663613, 0.77582577,\n",
       "        0.2352803 , 0.64164593, 0.59883191, 0.5282207 , 0.41659218,\n",
       "        0.63643123, 0.49075731, 0.11021041, 0.64573854, 0.99815272,\n",
       "        0.84498117, 0.92204435, 0.69444799, 0.6466703 , 0.82393698,\n",
       "        0.45211936, 0.18980481, 0.24317048, 0.39932527, 0.23965194,\n",
       "        0.65083227, 0.11527241, 0.35817003, 0.75344186, 0.86662218,\n",
       "        0.58369459, 0.96116902, 0.24034181, 0.46339814, 0.55205644,\n",
       "        0.34545971, 0.52829303, 0.03432445, 0.74085598, 0.34396928,\n",
       "        0.29478189, 0.28670507, 0.98063077, 0.94035418, 0.51810222,\n",
       "        0.30945736, 0.06413999, 0.96616105, 0.57125086, 0.90266588,\n",
       "        0.09162353, 0.1003956 , 0.84440645, 0.16776444, 0.63453002,\n",
       "        0.93196312, 0.5055781 , 0.53029985, 0.22290809, 0.37772018,\n",
       "        0.61711993, 0.69904158, 0.01248064, 0.95545462, 0.60605087,\n",
       "        0.93051483, 0.8268973 , 0.79831594, 0.70691864, 0.14934682,\n",
       "        0.02759929, 0.67061428, 0.86493179, 0.29319245, 0.5206955 ,\n",
       "        0.90000222, 0.72374852, 0.93566433, 0.47060502, 0.94643442]),\n",
       " 'W2': array([[-0.00089888, -0.00853277,  0.02048462, ...,  0.00455023,\n",
       "         -0.00229944,  0.02582686],\n",
       "        [-0.01105327,  0.00734967, -0.02525802, ...,  0.01425513,\n",
       "         -0.00227945,  0.00188002],\n",
       "        [-0.00092867,  0.0070088 , -0.00703424, ..., -0.01271858,\n",
       "          0.00725578,  0.01081538],\n",
       "        ...,\n",
       "        [-0.00398736,  0.0033769 ,  0.01068281, ..., -0.00762868,\n",
       "          0.00973012, -0.00162356],\n",
       "        [-0.0146405 , -0.00375539, -0.00474125, ...,  0.00097953,\n",
       "         -0.00683962, -0.00929615],\n",
       "        [-0.01982949,  0.00932425,  0.01142748, ..., -0.00640658,\n",
       "         -0.01256793,  0.00421833]]),\n",
       " 'b2': array([0.39617348, 0.37116565, 0.05420859, 0.95300203, 0.03430701,\n",
       "        0.361123  , 0.21113363, 0.11706623, 0.41696657, 0.19236606,\n",
       "        0.39234049, 0.96301775, 0.63556747, 0.20047846, 0.81989068,\n",
       "        0.80352892, 0.15500282, 0.05216417, 0.35523237, 0.89194004,\n",
       "        0.3716583 , 0.49223536, 0.0376044 , 0.34309204, 0.87532148,\n",
       "        0.93292368, 0.94245712, 0.01608775, 0.86416622, 0.9392883 ,\n",
       "        0.99989517, 0.1090521 , 0.91056348, 0.00311378, 0.47063982,\n",
       "        0.18638268, 0.06631158, 0.77397102, 0.90410146, 0.13748128,\n",
       "        0.77872403, 0.23204781, 0.12990676, 0.11374542, 0.26777536,\n",
       "        0.36660781, 0.40771923, 0.58870843, 0.70958724, 0.57160635,\n",
       "        0.0925799 , 0.72086056, 0.28732081, 0.83587369, 0.24224087,\n",
       "        0.05544259, 0.45698394, 0.0772178 , 0.99992189, 0.31790272,\n",
       "        0.45370516, 0.48115553, 0.06791771, 0.12716757, 0.43804393,\n",
       "        0.02571235, 0.31234861, 0.63145077, 0.81267899, 0.37617035,\n",
       "        0.71136063, 0.57445733, 0.68696315, 0.62522508, 0.59025519,\n",
       "        0.08821816, 0.73597443, 0.45880845, 0.60393255, 0.75587036,\n",
       "        0.13579894, 0.00966447, 0.05838608, 0.34711627, 0.25483957,\n",
       "        0.59884903, 0.8542867 , 0.73974889, 0.01781509, 0.74582892,\n",
       "        0.2850998 , 0.6456063 , 0.12948822, 0.99140096, 0.22551522,\n",
       "        0.04039198, 0.8190423 , 0.25658603, 0.36322244, 0.00780672,\n",
       "        0.61870213, 0.2800183 , 0.47499028, 0.99434123, 0.68450919,\n",
       "        0.36493871, 0.20282646, 0.65510826, 0.19124233, 0.08819274,\n",
       "        0.42769873, 0.05053081, 0.64125999, 0.37774321, 0.65318724,\n",
       "        0.25039709, 0.23097003, 0.31943893, 0.71299682, 0.44651437,\n",
       "        0.65711169, 0.32757842, 0.28290127, 0.7169499 , 0.10086223,\n",
       "        0.20545394, 0.84593815, 0.02595159, 0.97906245, 0.45433093,\n",
       "        0.73661433, 0.35541557, 0.86996965, 0.2403118 , 0.5830014 ,\n",
       "        0.78367847, 0.33142548, 0.73635492, 0.43351444, 0.04297794,\n",
       "        0.63785888, 0.52144625, 0.81820955, 0.38283818, 0.42214897,\n",
       "        0.30690501, 0.39492555, 0.91008837, 0.64380744, 0.31363999,\n",
       "        0.38815173, 0.18703937, 0.36002618, 0.54415948, 0.43076367,\n",
       "        0.82514271, 0.79361903, 0.49659983, 0.4461652 , 0.32295574,\n",
       "        0.46414558, 0.59868286, 0.11526196, 0.7510186 , 0.38137949,\n",
       "        0.0306297 , 0.80971723, 0.30246379, 0.25236194, 0.44927207,\n",
       "        0.40096493, 0.04085941, 0.70730375, 0.90033719, 0.14671716,\n",
       "        0.4535918 , 0.63176072, 0.00822028, 0.57965689, 0.75448488,\n",
       "        0.5944185 , 0.47572571, 0.74262986, 0.05547976, 0.07023527,\n",
       "        0.35332861, 0.36036227, 0.1017084 , 0.15266414, 0.02864668,\n",
       "        0.74551694, 0.42741581, 0.02689501, 0.39840858, 0.12570936,\n",
       "        0.43230986, 0.08071964, 0.74349297, 0.44170935, 0.68257227]),\n",
       " 'W3': array([[-0.00448784, -0.00797448,  0.0068101 , ...,  0.00886973,\n",
       "         -0.01727605,  0.00183542],\n",
       "        [-0.00581855,  0.00815293, -0.00182522, ...,  0.00486315,\n",
       "          0.01701466,  0.02123945],\n",
       "        [ 0.00317907, -0.0008115 ,  0.0188977 , ..., -0.01583443,\n",
       "          0.00429578, -0.01263981],\n",
       "        ...,\n",
       "        [ 0.00463554, -0.00210706,  0.01529592, ...,  0.00642466,\n",
       "          0.01249892,  0.00251346],\n",
       "        [-0.00948887, -0.00548783,  0.01734116, ...,  0.00275529,\n",
       "          0.00881197, -0.00851274],\n",
       "        [ 0.00884161, -0.00193247,  0.00555162, ...,  0.01344014,\n",
       "          0.01596236, -0.00116588]]),\n",
       " 'b3': array([0.94365238, 0.07936464, 0.51034115, 0.81633357, 0.26169866,\n",
       "        0.44698148, 0.45082249, 0.52960106, 0.69232073, 0.08728443])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題2】フォワードプロパゲーションの実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    C = x.max()\n",
    "    return np.exp(x - C) / np.exp(x - C).sum()\n",
    "\n",
    "def forward(X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    z3 = softmax(a3)\n",
    "    return z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題3】交差エントロピー誤差の実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.6  0.1  0.05 0.15]\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "t = np.array([2, 7, 0, 9, 4])\n",
    "y = np.array([0.1, 0.6, 0.1, 0.05, 0.15])\n",
    "print(y[np.arange(batch_size)])\n",
    "print(y.size)\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(a[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.dim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題4】バックプロパゲーションの実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vector = np.array([0, 2, 1, 3, 2])\n",
    "n_labels = len(np.unique(target_vector))\n",
    "np.eye(n_labels)[target_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward(X):\n",
    "        a1 = np.dot(X, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        z2 = sigmoid(a2)\n",
    "        a3 = np.dot(z2, W3) + b3\n",
    "        z3 = softmax(a3)\n",
    "        return z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 10)\n",
      "(48000, 784)\n"
     ]
    }
   ],
   "source": [
    "la = _forward(X_train)\n",
    "print(la.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cross_entropy_error(y, t):\n",
    "    batch_size = y.shape[0]\n",
    "    loss = -np.sum(t * np.log(y)) / batch_size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.104694925524985\n"
     ]
    }
   ],
   "source": [
    "print(_cross_entropy_error(la, y_train))\n",
    "# print(y_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "\n",
    "print(len(get_mini_batch)) # 2400\n",
    "#print(get_mini_batch[5]) # 5番目のミニバッチが取得できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "\n",
    "    def __init__(self, n_input, n_nodes1, n_nodes2, n_output, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        # 重みの初期化\n",
    "        params = {}\n",
    "        params['W1'] = sigma * np.random.randn(n_features, n_nodes1)\n",
    "        params['b1'] = np.random.rand(400)\n",
    "        params['W2'] = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        params['b2'] = np.random.rand(200)\n",
    "        params['W3'] = sigma * np.random.randn(n_nodes2, n_output)\n",
    "        params['b3'] = np.random.rand(10)\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "    def _softmax(self, x):\n",
    "        C = x.max()\n",
    "        return np.exp(x - C) / np.exp(x - C).sum()\n",
    "        \n",
    "    def _forward(self, X):\n",
    "        a1 = np.dot(X, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        z2 = sigmoid(a2)\n",
    "        a3 = np.dot(z2, W3) + b3\n",
    "        z3 = softmax(a3)\n",
    "        return z3\n",
    "    \n",
    "    def _cross_entropy_error(self, y, t):  \n",
    "        batch_size = y.shape[0]\n",
    "        loss = -np.sum(t * np.log(y)) / batch_size\n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題4】バックプロパゲーションの実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    # TODO: epoch複数に対応\n",
    "    def __init__(self, n_input, n_nodes1, n_nodes2, n_output, lr, epoch, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.n_input = n_input\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.sigma = 0.01\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        \n",
    "        # 重み、バイアスの初期化\n",
    "        np.random.seed(0)\n",
    "        self.W1 = self.sigma * np.random.randn(n_input, n_nodes1)\n",
    "        self.b1 = np.random.randn(n_nodes1)\n",
    "        self.W2 = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        self.b2 = np.random.randn(n_nodes2)\n",
    "        self.W3 = self.sigma * np.random.randn(n_nodes2, n_output)\n",
    "        self.b3 = np.random.randn(n_output)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        self.loss_list = []\n",
    "        for _ in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=20)\n",
    "            #self.loss_list = []\n",
    "            self.loss_sum = 0\n",
    "            # TODO: epochごとにlossを記録\n",
    "            # mini_batchごとの平均\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                a1, z1, a2, z2, a3, z3 = self._forward(mini_X_train)\n",
    "                self.loss = self._cross_entropy_error(z3, mini_y_train)\n",
    "                #self.loss_list.append(self.loss)\n",
    "                #self.loss_sum += self.loss\n",
    "                #self.loss_mean = self.loss_sum / batch_size\n",
    "                self.W1, self.b1, self.W2, self.b2, self.W3, self.b3 = self._backward(mini_X_train, z1, z2, z3, mini_y_train)\n",
    "            # print(self.W3.sum(axis=0))\n",
    "            self.loss_list.append(self.loss)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#         if self.verbose:\n",
    "#             #verboseをTrueにした際は学習過程などを出力する\n",
    "#             return loss_list\n",
    "#         pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        _, _, _, _, _, y = self._forward(X)\n",
    "        pred = np.argmax(y, axis=1)\n",
    "        return pred, y\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        C = np.max(x)\n",
    "        return 1 / (1 + np.exp(-x/C))\n",
    "    \n",
    "    def _d_sigmoid(self, x):\n",
    "        return self._sigmoid(x) * (1 - self._sigmoid(x))\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        # 出力の総和が1でない\n",
    "        C = np.max(x)\n",
    "        return np.exp(x / C) / np.exp(x / C).sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    def _cross_entropy_error(self, y, t):\n",
    "        size = 1\n",
    "        if y.ndim == 2:\n",
    "            size = y.shape[0]\n",
    "        return -np.sum(t * np.log(y)) / size\n",
    "    \n",
    "    def _forward(self, X):\n",
    "        a1 = np.dot(X, self.W1) + self.b1\n",
    "        z1 = self._sigmoid(a1)\n",
    "        a2 = np.dot(z1, self.W2) + self.b2\n",
    "        z2 = self._sigmoid(a2)\n",
    "        a3 = np.dot(z2, self.W3) + self.b3\n",
    "        z3 = self._softmax(a3)\n",
    "        return a1, z1, a2, z2, a3, z3\n",
    "    \n",
    "    def _backward(self, X, z1, z2, z3, t):\n",
    "        # z3 : (20, 10)\n",
    "        #print('z3 shape:', z3.shape)\n",
    "        # t : (20, 10)\n",
    "        #print('t shape', t.shape)\n",
    "        delta3 = z3 - t # delta3: \n",
    "        #print('delta3 shape', delta3.shape)\n",
    "        grad_b3 = np.sum(delta3, axis=0)\n",
    "        #print('grad_b3:', grad_b3.shape)\n",
    "        grad_W3 = np.dot(z2.T, delta3)\n",
    "        #print('grad_W3.shape:', grad_W3.shape)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W3.T) * self._d_sigmoid(z2)\n",
    "        grad_b2 = np.sum(delta2, axis=0)\n",
    "        grad_W2 = np.dot(z1.T, delta2)\n",
    "        \n",
    "        delta1 = np.dot(delta2, self.W2.T) * self._d_sigmoid(z1)\n",
    "        grad_b1 = np.sum(delta1, axis=0)\n",
    "        grad_W1 = np.dot(X.T, delta1)\n",
    "        \n",
    "        self.W1 -= self.lr * grad_W1\n",
    "        self.b1 -= self.lr * grad_b1\n",
    "        self.W2 -= self.lr * grad_W2\n",
    "        self.b2 -= self.lr * grad_b2\n",
    "        self.W3 -= self.lr * grad_W3\n",
    "        self.b3 -= self.lr * grad_b3\n",
    "        \n",
    "        return self.W1, self.b1, self.W2, self.b2, self.W3, self.b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchSimpleNeuralNetrowkClassifier(n_input=784, n_nodes1=400, n_nodes2=200, n_output=10, lr=0.000001, epoch=20)\n",
    "nn.fit(X_train, y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09877146 0.11424612 0.09917093 0.1014194  0.09607823 0.09007072\n",
      " 0.09918131 0.10416109 0.09700381 0.09989693] [1 1 1 ... 1 1 1]\n",
      "0 0\n",
      "1 12000\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n"
     ]
    }
   ],
   "source": [
    "a, b = nn.predict(X_val)\n",
    "print(b[0], a)\n",
    "for i in range(10):\n",
    "    print(i, len(a[a==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = ScratchSimpleNeuralNetrowkClassifier(n_input=784, n_nodes1=400, n_nodes2=200, n_output=10, lr=0.000000001, epoch=100)\n",
    "# nn.fit(X_train, y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = nn.predict(X_val)\n",
    "print(b[0], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchSimpleNeuralNetrowkClassifier(n_input=784, n_nodes1=400, n_nodes2=200, n_output=10, lr=0.1, epoch=100)\n",
    "nn.fit(X_train, y_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = nn.predict(X_val)\n",
    "print(b[0], a)\n",
    "print(len(a))\n",
    "print(np.mean(a))\n",
    "print(12006/12000)\n",
    "for i in range(10):\n",
    "    print(len(a[a==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x:(20, 10)\n",
    "np.ones((5, 3)).sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.W3[:, 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.W3.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.W3.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.755078400519433, 2.778787237064127, 2.798488350724543, 2.80385251592768, 2.7735111023943837, 2.6773449509614506, 2.517454327517451, 2.3758702259022875, 2.318365616262546, 2.3044643930219744, 2.301179579545493, 2.300408836129182, 2.3002282093338864, 2.3001858575818224, 2.3001759135379958, 2.3001735706793034, 2.30017301227085, 2.3001728731732043, 2.300172832700043, 2.3001728154466705]\n"
     ]
    }
   ],
   "source": [
    "print(nn.loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.loss_list)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
