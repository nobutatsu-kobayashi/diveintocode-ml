{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN 2D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題1】【問題2】**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  2.,  3.],\n",
       "         [ 5.,  6.,  7.],\n",
       "         [ 9., 10., 11.]],\n",
       "\n",
       "        [[ 2.,  3.,  4.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [10., 11., 12.]]],\n",
       "\n",
       "\n",
       "       [[[ 5.,  6.,  7.],\n",
       "         [ 9., 10., 11.],\n",
       "         [13., 14., 15.]],\n",
       "\n",
       "        [[ 6.,  7.,  8.],\n",
       "         [10., 11., 12.],\n",
       "         [14., 15., 16.]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3,4],\n",
    "              [5,6,7,8],\n",
    "              [9,10,11,12],\n",
    "              [13,14,15,16]])\n",
    "\n",
    "x_hat = np.zeros((2, 2, 3, 3))\n",
    "for oh in range(2):\n",
    "    for ow in range(2):\n",
    "        x_hat[oh, ow, :, :] = x[oh:oh+3, ow:ow+3]\n",
    "x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  2.],\n",
       "         [ 5.,  6.]],\n",
       "\n",
       "        [[ 2.,  3.],\n",
       "         [ 6.,  7.]],\n",
       "\n",
       "        [[ 3.,  4.],\n",
       "         [ 7.,  8.]]],\n",
       "\n",
       "\n",
       "       [[[ 5.,  6.],\n",
       "         [ 9., 10.]],\n",
       "\n",
       "        [[ 6.,  7.],\n",
       "         [10., 11.]],\n",
       "\n",
       "        [[ 7.,  8.],\n",
       "         [11., 12.]]],\n",
       "\n",
       "\n",
       "       [[[ 9., 10.],\n",
       "         [13., 14.]],\n",
       "\n",
       "        [[10., 11.],\n",
       "         [14., 15.]],\n",
       "\n",
       "        [[11., 12.],\n",
       "         [15., 16.]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat = np.zeros((3, 3, 2, 2))\n",
    "for fh in range(3):\n",
    "    for fw in range(3):\n",
    "        x_hat[fh, fw, :, :] = x[fh:fh+2, fw:fw+2]\n",
    "x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  2.,  3.],\n",
       "         [ 5.,  6.,  7.],\n",
       "         [ 9., 10., 11.]],\n",
       "\n",
       "        [[ 2.,  3.,  4.],\n",
       "         [ 6.,  7.,  8.],\n",
       "         [10., 11., 12.]]],\n",
       "\n",
       "\n",
       "       [[[ 5.,  6.,  7.],\n",
       "         [ 9., 10., 11.],\n",
       "         [13., 14., 15.]],\n",
       "\n",
       "        [[ 6.,  7.,  8.],\n",
       "         [10., 11., 12.],\n",
       "         [14., 15., 16.]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tilde = x_hat.transpose((2, 3, 0, 1))\n",
    "x_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.,  3.,  5.,  6.,  7.,  9., 10., 11.],\n",
       "        [ 2.,  3.,  4.,  6.,  7.,  8., 10., 11., 12.]],\n",
       "\n",
       "       [[ 5.,  6.,  7.,  9., 10., 11., 13., 14., 15.],\n",
       "        [ 6.,  7.,  8., 10., 11., 12., 14., 15., 16.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_col = x_tilde.reshape(2, 2, -1)\n",
    "x_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20., 23.],\n",
       "       [32., 35.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.array([[-1, 0, 1],\n",
    "              [0, 2, 1],\n",
    "              [1, -1, 0]])\n",
    "\n",
    "np.dot(x_col, f.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**im2col関数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, FH, FW):\n",
    "    H, W = X.shape\n",
    "    OH = H - FH + 1\n",
    "    OW = W - FW + 1\n",
    "    \n",
    "    X_hat = np.zeros((FH, FW, OH, OW))\n",
    "    for fh in range(FH):\n",
    "        for fw in range(FW):\n",
    "            X_hat[fh, fw, :, :] = X[fh:fh+OH, fw:fw+OW]\n",
    "    X_tilde = X_hat.transpose(2, 3, 0, 1)\n",
    "    X_col = X_tilde.reshape(OH, OW, -1)\n",
    "    return X_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.  2.  3.  5.  6.  7.  9. 10. 11.]\n",
      "  [ 2.  3.  4.  6.  7.  8. 10. 11. 12.]]\n",
      "\n",
      " [[ 5.  6.  7.  9. 10. 11. 13. 14. 15.]\n",
      "  [ 6.  7.  8. 10. 11. 12. 14. 15. 16.]]]\n",
      "[[20. 23.]\n",
      " [32. 35.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2, 3, 4],\n",
    "              [5, 6, 7, 8],\n",
    "              [9, 10, 11, 12],\n",
    "              [13, 14, 15, 16]])\n",
    "\n",
    "F = np.array([[-1, 0, 1],\n",
    "              [0, 2, 1],\n",
    "              [1, -1, 0]])\n",
    "\n",
    "X_col = im2col(X, 3, 3)\n",
    "print(X_col)\n",
    "print(np.dot(X_col, F.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  2,  3,  0],\n",
       "       [ 0,  4,  5,  6,  0],\n",
       "       [ 0,  8,  9, 10,  0],\n",
       "       [ 0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [8, 9, 10]])\n",
    "b = np.pad(a, [(1, 1), (1, 1)])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(6)\n",
    "a[0:6:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**im2col関数（stride, padding対応版）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, FH, FW, stride=1, pad=0):\n",
    "    H, W = X.shape\n",
    "    OH = (H + 2*pad - FH) // stride + 1 # 割り切れない場合は丸め込み\n",
    "    OW = (W + 2*pad - FW) // stride + 1\n",
    "    \n",
    "    X_hat = np.zeros((FH, FW, OH, OW))\n",
    "    for fh in range(FH):\n",
    "        for fw in range(FW):\n",
    "            X_hat[fh, fw, :, :] = X[fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "    X_tilde = X_hat.transpose(2, 3, 0, 1)\n",
    "    X_col = X_tilde.reshape(OH, OW, -1)\n",
    "    return X_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17., 23.],\n",
       "       [41., 47.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2, 3, 4],\n",
    "              [5, 6, 7, 8],\n",
    "              [9, 10, 11, 12],\n",
    "              [13, 14, 15, 16]])\n",
    "\n",
    "F = np.array([[-1, 1],\n",
    "              [2, 1]])\n",
    "\n",
    "X_col = im2col(X, 2, 2, stride=2, pad=0)\n",
    "np.dot(X_col, F.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X.shapeが(Batch, Channel, H, W)のときのim2col関数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データが4次元配列(mini_batch, channel, height, width)\n",
    "def im2col(X, FH, FW, stride=1, pad=0):\n",
    "    N, C, H, W = X.shape\n",
    "    OH = (H + 2*pad - FH) // stride + 1\n",
    "    OW = (W + 2*pad - FW) // stride + 1\n",
    "    \n",
    "    # (N, C, H, W)のうちHとW方向にのみpadding\n",
    "    X_pad = np.pad(X, [(0, 0), (0, 0), (pad, pad), (pad, pad)])\n",
    "    # さっきのものにN, Cをつける\n",
    "    X_hat = np.zeros((N, C, FH, FW, OH, OW))\n",
    "    for fh in range(FH):\n",
    "        for fw in range(FW):\n",
    "            X_hat[:, :, fh, fw, :, :] = X[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "    # 引き伸ばしてベクトルの内積計算に持ち込む\n",
    "    # 目標のshapeは(N, OH, OW, C*FH*FW)\n",
    "    X_tilde = X_hat.transpose(0, 4, 5, 1, 2, 3) # X_tilde.shape: (N, OH, OW, C, FH, FW)\n",
    "    X_col = X_tilde.reshape(N, OH, OW, -1)\n",
    "    return X_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 5, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "C = 3\n",
    "H = 7\n",
    "W = 7\n",
    "FN = 4\n",
    "FH = 3\n",
    "FW = 3\n",
    "# OH = 5\n",
    "# OW = 5\n",
    "\n",
    "X = np.random.rand(K, C, H, W)\n",
    "F = np.random.rand(FN, C, FH, FW)\n",
    "\n",
    "X_col = im2col(X, FH, FW, stride=1, pad=0)\n",
    "f_col = F.reshape(FN, -1).T # F.shape: (FN, C, FH, FW)\n",
    "# np.dot(X_col, f_col): (K, OH, OW, C*FH*FW)(FN, C*FH*FW) → (K, OH, OW, FN)\n",
    "y = np.dot(X_col, f_col).transpose(0, 3, 1, 2) # (K, OH, OW, FN) → (K, FN, OH, OW)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**とりあえずforwardまでのConv2dを作成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, F, b, stride=1, pad=0):\n",
    "        self.F = F\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, X):\n",
    "        N, C, H, W = X.shape\n",
    "        FN, C, FH, FW = self.F.shape\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 出力サイズ\n",
    "        OH = (H + 2*pad - FH) // stride + 1\n",
    "        OW = (W + 2*pad - FW) // stride + 1\n",
    "        \n",
    "        # (N, C, H, W)のうちH, W方向にのみpadding\n",
    "        X_pad = np.pad(X, [(0, 0), (0, 0), (pad, pad), (pad, pad)])\n",
    "        \n",
    "        # X_hat(空箱)を用意。型は(N, C, FH, FW, OH, OW)\n",
    "        X_hat = np.zeros((N, C, FH, FW, OH, OW))\n",
    "        \n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[:, :, fh, fw, :, :] = X_pad[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stirde:stride]\n",
    "                \n",
    "        # 引き伸ばしてベクトル内積計算に持ち込む\n",
    "        # 目標のX_col.shape: (N, OH, OW, C*FH*FW)\n",
    "        # まずは(N, OH, OW, C, FH, FW)にしたい\n",
    "        # X_hat.shape: (N, C, FH, FW, OH, OW)\n",
    "        X_tilde = X_hat.transpose(0, 4, 5, 1, 2, 3) # X_tilde.shape: (N, OH, OW, C, FH, FW)\n",
    "        X_col = X_tilde.reshape(N, OH, OW, -1) # (N, OH, OW, C*FH*FW)\n",
    "        \n",
    "        # 出力yを計算\n",
    "        F_col = self.F.reshape(FN, -1).T # F_col.shape: (FN, C*FH*FW) → (C*FH*FW, FN)\n",
    "        # np.dot(X_col, F_col).shape: (N, OH, OW, FN)\n",
    "        # y.shape: (N, FN, OH, OW)\n",
    "        # transpose(0, 3, 1, 2)\n",
    "        # b.shape: (FN,)\n",
    "        y = (np.dot(X_col, F_col) + self.b).transpose(0, 3, 1, 2) # (N, FN, OH, OW)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**backwardを考える**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = np.array([[1, 2],\n",
    "               [3, 4]])\n",
    "\n",
    "F = np.array([[1, 1, 0],\n",
    "              [1, 0, 1],\n",
    "              [0, 1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結局やりたいことは、ロスの出力による偏微分と入力のテンソル積\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w_{st}} = \\sum_{i}^{M-m} \\sum_{j}^{N-n} \\frac{\\partial L}{\\partial y_{ij}} x_{(i+s)(j+t)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1]\n",
      "  [2]]\n",
      "\n",
      " [[3]\n",
      "  [4]]]\n",
      "[[[1 1 0]]\n",
      "\n",
      " [[1 0 1]]\n",
      "\n",
      " [[0 1 1]]]\n",
      "(2, 2, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dy.reshape(2, 2, 1))\n",
    "print(F.reshape(3, 1, 3))\n",
    "dX_tilde = np.dot(dy.reshape(2, 2, 1), F.reshape(3, 1, 3))\n",
    "print(dX_tilde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 3. 2. 0.]\n",
      " [4. 9. 5. 2.]\n",
      " [3. 5. 6. 6.]\n",
      " [0. 3. 7. 4.]]\n"
     ]
    }
   ],
   "source": [
    "dX = np.zeros((4, 4))\n",
    "\n",
    "for fh in range(3):\n",
    "    for fw in range(3):\n",
    "        dX[fh:fh+2, fw:fw+2] += dX_tilde[:, :, fh, fw]\n",
    "        \n",
    "print(dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_hat.shape: (3, 3, 2, 2)\n",
      "Xh_col.shape: (3, 3, 4)\n",
      "dF: [[17. 17. 17.]\n",
      " [27. 27. 27.]\n",
      " [37. 37. 37.]] db: 10\n"
     ]
    }
   ],
   "source": [
    "dy = np.array([[1, 2],\n",
    "               [3, 4]])\n",
    "\n",
    "X = np.array([[1, 1, 1, 1],\n",
    "              [2, 2, 2, 2],\n",
    "              [3, 3, 3, 3],\n",
    "              [4, 4, 4, 4]])\n",
    "X_hat = np.zeros((3, 3, 2, 2))\n",
    "for fh in range(3):\n",
    "    for fw in range(3):\n",
    "        X_hat[fh, fw, :, :] = X[fh:fh+2, fw:fw+2]\n",
    "\n",
    "print('X_hat.shape:', X_hat.shape)\n",
    "Xh_col = X_hat.reshape(3, 3, -1)\n",
    "print('Xh_col.shape:', Xh_col.shape)\n",
    "dF = np.dot(Xh_col, dy.flatten())\n",
    "db = dy.sum()\n",
    "print('dF:', dF, 'db:', db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**backwardも含めた完成版**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(self, F, b, stride=1, pad=0):\n",
    "        self.F = F\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # backward用\n",
    "        self.X_hat = None\n",
    "        self.F_col = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        N, C, H, W = X.shape\n",
    "        FN, C, FH, FW = self.F.shape\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 出力サイズ\n",
    "        OH = (H + 2*pad - FH) // stride + 1\n",
    "        OW = (W + 2*pad - FW) // stride + 1\n",
    "        \n",
    "        # (N, C, H, W)のうちH, W方向にのみpadding\n",
    "        X_pad = np.pad(X, [(0, 0), (0, 0), (pad, pad), (pad, pad)])\n",
    "        \n",
    "        # X_hat(空箱)を用意。型は(N, C, FH, FW, OH, OW)\n",
    "        X_hat = np.zeros((N, C, FH, FW, OH, OW))\n",
    "        \n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[:, :, fh, fw, :, :] = X_pad[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stirde:stride]\n",
    "                \n",
    "        # 引き伸ばしてベクトル内積計算に持ち込む\n",
    "        # 目標のX_col.shape: (N, OH, OW, C*FH*FW)\n",
    "        # まずは(N, OH, OW, C, FH, FW)にしたい\n",
    "        # X_hat.shape: (N, C, FH, FW, OH, OW)\n",
    "        X_tilde = X_hat.transpose(0, 4, 5, 1, 2, 3) # X_tilde.shape: (N, OH, OW, C, FH, FW)\n",
    "        X_col = X_tilde.reshape(N, OH, OW, -1) # (N, OH, OW, C*FH*FW)\n",
    "        \n",
    "        # 出力yを計算\n",
    "        F_col = self.F.reshape(FN, -1).T # F_col.shape: (FN, C*FH*FW) → (C*FH*FW, FN)\n",
    "        # np.dot(X_col, F_col).shape: (N, OH, OW, FN)\n",
    "        # y.shape: (N, FN, OH, OW)\n",
    "        # transpose(0, 3, 1, 2)\n",
    "        # b.shape: (FN,)\n",
    "        y = (np.dot(X_col, F_col) + self.b).transpose(0, 3, 1, 2) # (N, FN, OH, OW)\n",
    "        \n",
    "        # backwardで使うから保存\n",
    "        self.X_hat = X_hat\n",
    "        self.F_col = F_col\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        N, FN, OH, OW = dy.shape\n",
    "        FN, C, FH, FW = self.F.shape\n",
    "        N, C, H, W = self.X.shape\n",
    "        stride = self.stride\n",
    "        pad = self.pad\n",
    "        \n",
    "        # dF, dbを算出\n",
    "        # X_hat.shape: (N, C, FH, FW, OH, OW)\n",
    "        # X_hat_col.shape: (C, FH, FW, -1)\n",
    "        # とりあえずの目標shape: (C, FH, FW, N, OH, OW)\n",
    "        X_hat_col = self.X_hat.transpose(1, 2, 3, 0, 4, 5).reshape(C, FH, FW, -1)\n",
    "        # dy.shape: (N, FN, OH, OW)\n",
    "        # dy_col.shapeは(FN, -1)にしたい\n",
    "        # まずは(FN, N, OH, OW)にtranspose\n",
    "        dy_col = dy.transpose(1, 0, 2, 3).reshape(FN, -1) # dy_col.shape: (FN, -1)\n",
    "        self.db = dy_col.sum(axis=1) # db.shape: (FN,)\n",
    "        # (FN, N*OH*OW)(C, FH, FW, N*OH*OW) → (FN, C, FH, FW)\n",
    "        self.dF = np.dot(dy_col, X_hat_col.transpose(0, 1, 3, 2))\n",
    "        \n",
    "        # (N, OH, OW, FN)(C, FH, FN, FW) → (N, OH, OW, C, FH, FW)\n",
    "        dX_tilde = np.dot(dy.transpose(0, 2, 3, 1), self.F.transpose(1, 2, 0, 3))\n",
    "        \n",
    "        # dX_tildeからdXを算出\n",
    "        dX = np.zeros((N, C, H+2*pad+stride-1, W+2*pad+stride-1))\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                dX[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride] += dX_tilde[:, :, :, :, fh, fw]\n",
    "                \n",
    "        return dX[:, :, pad:H+pad, pad:W+pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題3】最大プーリング層の作成**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**まずは2次元配列の場合を考える**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, S):\n",
    "        self.S = S\n",
    "        \n",
    "        # backward用\n",
    "        self.argmax = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        H, W = X.shape\n",
    "        S = self.S\n",
    "        FH, FW = S, S\n",
    "        stride = S\n",
    "\n",
    "        # 出力サイズ\n",
    "        OH = H // S\n",
    "        OW = W // S\n",
    "        \n",
    "        X_hat = np.zeros((FH, FW, OH, OW))\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[fh, fw, :, :] = X[fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "        X_tilde = X_hat.transpose(2, 3, 0, 1) # (OH, OW, FH, FW)\n",
    "        X_col = X_tilde.reshape(OH, OW, -1) # (OH, OW, FH*FW)\n",
    "        \n",
    "        y = X_col.max(axis=2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(16).reshape(4, 4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  7.],\n",
       "       [13., 15.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = Pooling(2)\n",
    "pool.forward(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N, Cを加えたものを考える**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, S):\n",
    "        self.S = S\n",
    "        \n",
    "        # backward用\n",
    "        self.argmax = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        N, C, H, W = X.shape\n",
    "        S = self.S\n",
    "        FH, FW = S, S\n",
    "        stride = S\n",
    "\n",
    "        # 出力サイズ\n",
    "        OH = H // S\n",
    "        OW = W // S\n",
    "        \n",
    "        X_hat = np.zeros((N, C, FH, FW, OH, OW))\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[:, :, fh, fw, :, :] = X[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "        X_tilde = X_hat.transpose(0, 1, 4, 5, 2, 3) # (N, C, OH, OW, FH, FW)\n",
    "        X_col = X_tilde.reshape(N, C, OH, OW, -1) # (N, C, OH, OW, FH*FW)\n",
    "        \n",
    "        y = X_col.max(axis=4) # (N, C, OH, OW)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8],\n",
       "         [16, 15, 14, 13],\n",
       "         [12, 11, 10,  9]],\n",
       "\n",
       "        [[ 4,  3,  2,  1],\n",
       "         [ 8,  7,  6,  5],\n",
       "         [12, 11, 10,  9],\n",
       "         [16, 15, 14, 13]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4次元配列\n",
    "x = np.array([[[[1, 2, 3, 4], [5, 6, 7, 8], [16, 15, 14, 13], [12, 11, 10, 9]],\n",
    "              [[4, 3, 2, 1], [8, 7, 6, 5], [12, 11, 10, 9], [16, 15, 14, 13]]]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 6.,  8.],\n",
       "         [16., 14.]],\n",
       "\n",
       "        [[ 8.,  6.],\n",
       "         [16., 14.]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = MaxPool2D(2)\n",
    "pool.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**backwardも含めたPoolingクラスを考える**\n",
    "\n",
    "逆伝搬における畳み込み層との最大の違いは，入力  X  を変形した配列である  X_tilde   とフィルターとの内積をとる代わりに，最大値をとっている点\n",
    "\n",
    "$$ y = max([x_0, x_1, ..., x_{i-1}]) $$\n",
    "\n",
    "を考える。どのx_iで最大値を取ったのかで状況は変わる。\n",
    "\n",
    "$$ \\frac{\\partial y}{\\partial x_i} = 1 (y = x_i), 0 (otherwise) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmax(x):\n",
    "    dx = np.zeros_like(x)\n",
    "    i = x.argmax()\n",
    "    dx[i] = 1\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([3, 3, 9, 7, 2, 1, 3, 5])\n",
    "dmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmax2(x):\n",
    "    I = x.shape[0]\n",
    "    print('I:', I)\n",
    "    y = x.max(axis=1)\n",
    "    print('y:', y)\n",
    "    arg = x.argmax(axis=1)\n",
    "    print('arg:', arg)\n",
    "    \n",
    "    dy = y\n",
    "    print('dy:', dy)\n",
    "    dx = np.zeros_like(x)\n",
    "    print('dx:', dx)\n",
    "    dx[np.arange(I), arg] = dy\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 3\n",
      "y: [12  9  8]\n",
      "arg: [3 1 0]\n",
      "dy: [12  9  8]\n",
      "dx: [[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, 12],\n",
       "       [ 0,  9,  0,  0],\n",
       "       [ 8,  0,  0,  0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[3, 5, 2, 12],\n",
    "              [7, 9, 2, 3],\n",
    "             [8, 2, 8, 4]])\n",
    "\n",
    "dmax2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**backwardも含めたPoolingクラス完成版**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, S):\n",
    "        self.S = S\n",
    "        \n",
    "        # backward用\n",
    "        self.argmax = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        N, C, H, W = X.shape\n",
    "        S = self.S\n",
    "        FH, FW = S, S\n",
    "        stride = S\n",
    "\n",
    "        # 出力サイズ\n",
    "        OH = H // S\n",
    "        OW = W // S\n",
    "        \n",
    "        X_hat = np.zeros((N, C, FH, FW, OH, OW))\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[:, :, fh, fw, :, :] = X[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "        X_tilde = X_hat.transpose(0, 1, 4, 5, 2, 3) # (N, C, OH, OW, FH, FW)\n",
    "        X_col = X_tilde.reshape(N, C, OH, OW, -1) # (N, C, OH, OW, FH*FW)\n",
    "        \n",
    "        y = X_col.max(axis=4) # (N, C, OH, OW)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        N, C, H, W = self.X.shape\n",
    "        N, C, OH, OW = dy.shape\n",
    "        S = self.S\n",
    "        FH, FW = S, S \n",
    "        stride = S\n",
    "   \n",
    "        # dy と　self.argmax から dX_tilde を計算\n",
    "        dX_tilde = np.zeros((N*C*OH*OW, FH*FW))\n",
    "        # (N*C*OH*OW, FH*FW) =  (N*C*OH*OW)\n",
    "        dX_tilde[np.arange(N*C*OH*OW), self.argmax] = dy.flatten()\n",
    "        dX_tilde = dX_tilde.reshape(N, C, OH, OW, FH, FW) \n",
    "        \n",
    "        #  dX_tilde から dX を計算\n",
    "        dX = np.zeros((N, C, H+stride-1, W+stride-1))  \n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                dx[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride] += dX_tilde[:, :, :, :, fh, fw]\n",
    "    \n",
    "        return dx[:, :, :H, :W]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題4】（アドバンス課題）平均プーリングの作成**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**forwardのみ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePooling:\n",
    "    def __init__(self, S):\n",
    "        self.S = S\n",
    "        \n",
    "    def forward(self, X):\n",
    "        H, W = X.shape\n",
    "        S = self.S\n",
    "        FH, FW = S, S\n",
    "        stride = S\n",
    "\n",
    "        # 出力サイズ\n",
    "        OH = H // S\n",
    "        OW = W // S\n",
    "        \n",
    "        X_hat = np.zeros((FH, FW, OH, OW))\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[fh, fw, :, :] = X[fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "        X_tilde = X_hat.transpose(2, 3, 0, 1) # (OH, OW, FH, FW)\n",
    "        X_col = X_tilde.reshape(OH, OW, -1) # (OH, OW, FH*FW)\n",
    "        \n",
    "        y = X_col.mean(axis=2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(16).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.5,  4.5],\n",
       "       [10.5, 12.5]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avepool = AveragePooling(2)\n",
    "avepool.forward(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**backwardも込み**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePooling:\n",
    "    def __init__(self, S):\n",
    "        self.S = S\n",
    "        \n",
    "        # backward用\n",
    "        self.argmax = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        H, W = X.shape\n",
    "        S = self.S\n",
    "        FH, FW = S, S\n",
    "        stride = S\n",
    "\n",
    "        # 出力サイズ\n",
    "        OH = H // S\n",
    "        OW = W // S\n",
    "        \n",
    "        X_hat = np.zeros((FH, FW, OH, OW))\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[fh, fw, :, :] = X[fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "        X_tilde = X_hat.transpose(2, 3, 0, 1) # (OH, OW, FH, FW)\n",
    "        X_col = X_tilde.reshape(OH, OW, -1) # (OH, OW, FH*FW)\n",
    "        \n",
    "        y = X_col.mean(axis=2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題5】平滑化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.N, self.C, self.H, self.W = self.X.shape\n",
    "        y = self.X.flatten()\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        self.dy = dy\n",
    "        dX = self.dy.reshape(self.N, self.C, self.H, self.W)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[[1, 2, 3, 4], [5, 6, 7, 8], [16, 15, 14, 13], [12, 11, 10, 9]],\n",
    "              [[4, 3, 2, 1], [8, 7, 6, 5], [12, 11, 10, 9], [16, 15, 14, 13]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8, 16, 15, 14, 13, 12, 11, 10,  9,  4,\n",
       "        3,  2,  1,  8,  7,  6,  5, 12, 11, 10,  9, 16, 15, 14, 13])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = Flatten()\n",
    "flatten.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15]],\n",
       "\n",
       "        [[16, 17, 18, 19],\n",
       "         [20, 21, 22, 23],\n",
       "         [24, 25, 26, 27],\n",
       "         [28, 29, 30, 31]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy = np.arange(32)\n",
    "flatten.backward(dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **【問題6】学習と推定**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "X_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape:', X_train.shape)\n",
    "print('y_train.shape:', y_train.shape)\n",
    "print('X_test.shape:', X_test.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].reshape(1, 28, 28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(X_train.shape[0], 1, 28, 28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 1, 28, 28)\n",
      "X_test.shape: (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape:', X_train.shape)\n",
    "print('X_test.shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for key in params:\n",
    "            params[key] -= self.lr * grads[key]\n",
    "            \n",
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key in params:\n",
    "                self.h[key] = np.zeros_like(params[key])\n",
    "                \n",
    "        for key in params:\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):   \n",
    "    # a がベクトルのとき\n",
    "    if a.ndim == 1:\n",
    "        c = np.max(a)#オーバーフロー対策1\n",
    "        x = a-c\n",
    "        x = 709*(x >= 709) + x*(x<709)#オーバーフロー対策2\n",
    "        exp_x = np.exp(x)\n",
    "        sum_exp_x = np.sum(exp_x)\n",
    "        return exp_x/sum_exp_x\n",
    "    \n",
    "    # a が２階の配列のとき\n",
    "    a = a.T\n",
    "    c = np.max(a, axis=0) #オーバーフロー対策1\n",
    "    x = a - c\n",
    "    x = 709*(x >= 709) + x*(x<709) #オーバーフロー対策2\n",
    "    exp_x = np.exp(x)\n",
    "    sum_exp_x = np.sum(exp_x, axis=0)\n",
    "    return (exp_x/sum_exp_x).T\n",
    "\n",
    "def sigmoid(x):\n",
    "    x = -709*(x <= -709)+709*(x >= 709) + x*(x>-709) *(x<709) #オーバーフロー対策\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.Xshape = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.Xshape = X.shape\n",
    "        X = X.reshape(self.Xshape[0], -1)\n",
    "        \n",
    "        self.X = X\n",
    "        A = np.dot(self.X, self.W) + self.b\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        self.dW = np.dot(self.X.T, dZ)\n",
    "        self.db = np.sum(dZ, axis=0)\n",
    "        dX = np.dot(dZ, self.W.T)\n",
    "        \n",
    "        dX = dX.reshape(*self.Xshape)\n",
    "        return dX\n",
    "    \n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.mask = (X > 0)\n",
    "        y = X * self.mask\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        dX = dy * self.mask\n",
    "        return dX\n",
    "    \n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        sely.y = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.y = sigmoid(X)\n",
    "        return self.y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        dX = dy * (1 - self.y) * self.y\n",
    "        return dX\n",
    "    \n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, X, t):\n",
    "        y = softmax(X)\n",
    "        self.y = y\n",
    "        self.t = t\n",
    "        batch_size = y.shape[0]\n",
    "        return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "    \n",
    "    def backward(self):\n",
    "        batch_size = self.y.shape[0]\n",
    "        dX = (self.y - self.t) / batch_size\n",
    "        return dX\n",
    "    \n",
    "class Convolution:\n",
    "    def __init__(self, F, b, stride=1, pad=0):\n",
    "        self.F = F\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.Xshape = None\n",
    "        self.X_hat = None\n",
    "        self.f_col = None\n",
    "        \n",
    "        self.dF = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.Xshape = X.shape\n",
    "        FN, C, FH, FW = self.F.shape\n",
    "        N, C, H, W = self.Xshape\n",
    "        pad = self.pad\n",
    "        stride = self.stride\n",
    "        \n",
    "        OH = (H + 2*pad - FH) // stride + 1\n",
    "        OW = (W + 2*pad - FW) // stride + 1\n",
    "        \n",
    "        X_pad = np.pad(X, [(0, 0), (0, 0), (pad, pad), (pad, pad)])\n",
    "        X_hat = np.zeros((N, C, FH, FW, OH, OW))\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[:, :, fh, fw, :, :] = X_pad[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "        X_tilde = X_hat.transpose(0, 4, 5, 1, 2, 3)\n",
    "        X_col = X_tilde.reshape(N, OH, OW, -1)\n",
    "        \n",
    "        f_col = self.F.reshape(FN, -1).T\n",
    "        y = (np.dot(X_col, f_col) + self.b).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.X_hat = X_hat\n",
    "        self.f_col = f_col\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        FN, C, FH, FW = self.F.shape\n",
    "        N, FN, OH, OW = dy.shape\n",
    "        N, C, H, W = self.Xshape\n",
    "        stride = self.stride\n",
    "        pad = self.pad\n",
    "        \n",
    "        X_hat_col = self.X_hat.transpose(1, 2, 3, 0, 4, 5).reshape(C, FH, FW, -1)\n",
    "        dy_col = dy.transpose(1, 0, 2, 3).reshape(FN, -1)\n",
    "        self.db = dy_col.sum(axis=1)\n",
    "        self.dF = np.dot(dy_col, X_hat_col.transpose(0, 1, 3, 2))\n",
    "        \n",
    "        dX_tilde = np.dot(dy.transpose(0, 2, 3, 1), self.F.transpose(1, 2, 0, 3))\n",
    "        dX_tilde = dX_tilde.transpose(0, 3, 1, 2, 4, 5)\n",
    "        \n",
    "        dX = np.zeros((N, C, H+2*pad+stride-1, W+2*pad+stride-1), dtype=np.float)\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                dX[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride] += dX_tilde[:, :, :, :, fh, fw]\n",
    "        return dX[:, :, pad:H+pad, pad:W+pad]\n",
    "    \n",
    "class MaxPool2D:\n",
    "    def __init__(self, S):\n",
    "        self.S = S\n",
    "        \n",
    "        # backward用\n",
    "        self.Xshape = None\n",
    "        self.argmax = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.Xshape = X.shape\n",
    "        N, C, H, W = X.shape\n",
    "        S = self.S\n",
    "        FH, FW = S, S\n",
    "        stride = S\n",
    "\n",
    "        # 出力サイズ\n",
    "        OH = H // S\n",
    "        OW = W // S\n",
    "        \n",
    "        X_hat = np.zeros((N, C, FH, FW, OH, OW))\n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                X_hat[:, :, fh, fw, :, :] = X[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride]\n",
    "        X_tilde = X_hat.transpose(0, 1, 4, 5, 2, 3) # (N, C, OH, OW, FH, FW)\n",
    "        X_col = X_tilde.reshape(N, C, OH, OW, -1) # (N, C, OH, OW, FH*FW)\n",
    "        \n",
    "        self.argmax = X_col.argmax(axis=-1).flatten()\n",
    "        \n",
    "        y = X_col.max(axis=4) # (N, C, OH, OW)\n",
    "        return y\n",
    "    \n",
    "    def backward(self, dy):\n",
    "        N, C, H, W = self.Xshape\n",
    "        N, C, OH, OW = dy.shape\n",
    "        S = self.S\n",
    "        FH, FW = S, S \n",
    "        stride = S\n",
    "   \n",
    "        # dy と　self.argmax から dX_tilde を計算\n",
    "        dX_tilde = np.zeros((N*C*OH*OW, FH*FW))\n",
    "        # (N*C*OH*OW, FH*FW) =  (N*C*OH*OW)\n",
    "        dX_tilde[np.arange(N*C*OH*OW), self.argmax] = dy.flatten()\n",
    "        dX_tilde = dX_tilde.reshape(N, C, OH, OW, FH, FW) \n",
    "        \n",
    "        #  dX_tilde から dX を計算\n",
    "        dX = np.zeros((N, C, H+stride-1, W+stride-1))  \n",
    "        for fh in range(FH):\n",
    "            for fw in range(FW):\n",
    "                dx[:, :, fh:fh+OH*stride:stride, fw:fw+OW*stride:stride] += dX_tilde[:, :, :, :, fh, fw]\n",
    "    \n",
    "        return dx[:, :, :H, :W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, input_dim=(1, 28, 28), optimizer=AdaGrad):\n",
    "        self.all_dim_list = [input_dim]\n",
    "        self.params = {}\n",
    "        self.optimizer = optimizer()\n",
    "        self.layers = OrderedDict()\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        self.idx = 0\n",
    "        \n",
    "    def affine(self, size, activation='relu'):\n",
    "        self.idx += 1\n",
    "        idx = self.idx\n",
    "        self.all_dim_list.append(size)\n",
    "        \n",
    "        # Heの初期化\n",
    "        sigma = np.sqrt(2 / np.prod(self.all_dim_list[idx - 1]))\n",
    "        self.params['W' + str(idx)] = sigma * np.random.randn(np.prod(self.all_dim_list[idx - 1]), size)\n",
    "        self.params['b' + str(idx)] = np.zeros(size)\n",
    "        \n",
    "        # Affine層の追加\n",
    "        self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)], self.params['b' + str(idx)])\n",
    "        \n",
    "        if activation == 'relu':\n",
    "            self.layers['Relu' + str(idx)] = Relu()\n",
    "        if activation == 'sigmoid':\n",
    "            self.layers['Sigmoid' + str(idx)] = Sigmoid()\n",
    "            \n",
    "    def convolution(self, FN, FH, FW, stride=1, pad=0, S=1, activation=None):\n",
    "        self.idx += 1\n",
    "        idx = self.idx\n",
    "        C, H, W = self.all_dim_list[idx - 1]\n",
    "        \n",
    "        OH = (H + 2*pad - FH) // stride + 1\n",
    "        OW = (W + 2*pad - FW) // stride + 1\n",
    "        \n",
    "        sigma = np.sqrt((2 / (C*FH*FW)))\n",
    "        self.params['F' + str(idx)] = sigma * np.random.randn(FN, C, FH, FW)\n",
    "        self.params['b' + str(idx)] = sigma * np.random.randn(FN)\n",
    "        \n",
    "        self.layers['Conv' + str(idx)] = Convolution(self.params['F' + str(idx)], self.params['b' + str(idx)], stride=stride, pad=pad)\n",
    "        \n",
    "        # 活性化層の追加\n",
    "        if activation == 'relu':\n",
    "            self.layers['Relu' + str(idx)] = Relu()\n",
    "        if activation == 'sigmoid':\n",
    "            self.layers['Sigmoid' + str(idx)] = Sigmoid()\n",
    "        \n",
    "        if S > 1:\n",
    "            self.layers['Pooling' + str(idx)] = MaxPool2D(S)\n",
    "            OH = OH // S\n",
    "            OW = OW // S\n",
    "        \n",
    "        self.all_dim_list.append((FN, OH, OW))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        for key, layer in self.layers.items():\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def loss(self, X, t):\n",
    "        y = self.predict(X)\n",
    "        print('y.shape:', y.shape)\n",
    "        print('t.shape:', t.shape)\n",
    "        return self.lastLayer.forward(X, t)\n",
    "    \n",
    "    def accuracy(self, X, t, batch_size=100):\n",
    "        acc = 0\n",
    "        for i in range(int(X.shape[0] / batch_size)):\n",
    "            tx = X[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            #print('tt.shape:', tt.shape)\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            tt = np.argmax(tt)\n",
    "            acc += np.sum(y == tt)   \n",
    "        return acc / X.shape[0]\n",
    "    \n",
    "    def gradient(self, X, t):\n",
    "        self.loss(X, t)\n",
    "        dy = self.lastLayer.backward()\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dy = layer.backward(dy)\n",
    "            \n",
    "        grads = {}\n",
    "        all_num = len(self.all_dim_slist)\n",
    "        \n",
    "        for idx in range(1, all_num):\n",
    "            if type(self.all_dim_list[idx]) == int:\n",
    "                grads['W' + str(idx)] = self.layers['Affine' + str(idx)].dW + self.params['W' + str(idx)]\n",
    "                grads['b' + str(idx)] = self.layers['Affine' + str(idx)].db\n",
    "            else:\n",
    "                grads['F' + str(idx)] = self.layers['Conv' + str(idx)].dF + self.params['F' + str(idx)]\n",
    "                grads['b' + str(idx)] = self.layers['Conv' + str(idx)].fb\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_test, y_test, iters_num=1000, batch_size=100):\n",
    "        self.train_accuracy_list = []\n",
    "        optimizer = self.optimizer\n",
    "        train_size = X_train.shape[0]\n",
    "        \n",
    "        for i in range(iters_num):\n",
    "            if i%int(iters_num/20) == 0:\n",
    "                accuracy = self.accuracy(X_test, y_test)\n",
    "                self.train_accuracy_list.append(accuracy)\n",
    "                print('iteration =', i, ', accuracy = ', accuracy)\n",
    "                \n",
    "            batch_mask = np.random.choice(train_size, batch_size, replace=False)\n",
    "            X_batch = X_train[batch_mask]\n",
    "            t_batch = y_train[batch_mask]\n",
    "            print('X_batch:', X_batch.shape)\n",
    "            \n",
    "            grads = self.gradient(X_batch, t_batch)\n",
    "            optimizer.update(self.params, grads)\n",
    "            \n",
    "        accuracy = self.accuracy(X_test, t_test)\n",
    "        self.train_accuracy_list.append(accuracy)\n",
    "        print('iteration = ', iters_num, ', accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CNN(input_dim=(1, 28, 28), optimizer=AdaGrad)\n",
    "network.convolution(FN=30, FH=5, FW=5, S=2, activation='relu')\n",
    "network.affine(100)\n",
    "network.affine(10, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 28, 28), (30, 12, 12), 100, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv1', <__main__.Convolution at 0xb41db1fd0>),\n",
       "             ('Relu1', <__main__.Relu at 0xb41db1b38>),\n",
       "             ('Pooling1', <__main__.MaxPool2D at 0xb41db1f60>),\n",
       "             ('Affine2', <__main__.Affine at 0xb41db1080>),\n",
       "             ('Relu2', <__main__.Relu at 0x121f39198>),\n",
       "             ('Affine3', <__main__.Affine at 0x121f39b70>)])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(network.all_dim_list)\n",
    "network.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 0 , accuracy =  0.0697\n",
      "X_batch: (100, 1, 28, 28)\n",
      "y.shape: (100, 10)\n",
      "t.shape: (100,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,) (100,1,28,28) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-224a5427983e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_accuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AdaGrad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-317a856837ed>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_test, y_test, iters_num, batch_size)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_batch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-317a856837ed>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, X, t)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-317a856837ed>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, X, t)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y.shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't.shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-6c422a715d36>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, t)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,) (100,1,28,28) "
     ]
    }
   ],
   "source": [
    "network.fit(X_train, y_train, X_test, y_test, iters_num=1000, batch_size=100)\n",
    "X = np.arange(0, len(network.train_accuracy_list), 1)\n",
    "plt.plot(X, network.train_accuracy_list, label='AdaGrad')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
